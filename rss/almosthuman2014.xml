<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>机器之心 - chuansong.me</title><link>http://chuansong.me/account/almosthuman2014</link><description>人与科技的美好关系</description><lastBuildDate>Fri, 30 Dec 2016 11:57:10 -0000</lastBuildDate><ttl>10</ttl><item><title>深度 | 大脑如何思考？科学家正用机器学习解码人类智能</title><link>http://chuansong.me/n/1417253342275</link><description>&lt;div class="rich_media_content " id="js_content"&gt;
&lt;section style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; background-color: rgb(117, 117, 118); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自Vox&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 14px; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;为什么我们需要人工智能协助研究人类的天生才智（natural intelligence）。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;过去几年中，&lt;a csmlink="GHoicc" href="http://chuansong.me/n/358775442602" target="_blank"&gt;Jack Gallant &lt;/a&gt;的神经科学实验室已经发表了一串听起来有些荒诞的论文。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2011 年，实验室证实，仅通过观察人类观影时的脑部活动，就可能再造电影片段。某种意义上，扫描观影人大脑再用计算机生成这部电影就像是读心术。类似地，2015 年，这个团队通过观察人类大脑活动成功预测了被试脑中勾勒着的名画。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2016 年，该团队在《自然》上发表了著名论文，宣布画出一万多个单个语词在大脑中的位置地图——方法是让被试收听 podcast 节目。（&lt;a csmlink="QHoicc" href="http://chuansong.me/n/306475142408" target="_blank"&gt; Nature 封面：神经科学家成功绘制大脑语义地图，解读人类思想迈出关键一步&lt;/a&gt;）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;他们怎么做到的？研究人员使用了机器学习工具——一种人工智能——挖掘海量大脑数据、找到了大脑活动模式、预测人类感知。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;不过，他们的目标并不是要打造一台读心机器。神经科学家对盗取藏在脑中的密码不感兴趣，也对那些见不得光的秘密不感冒。他们的目标更加远大。将神经科学转变为一种「大数据」科学，使用机器学习挖掘数据，Gallant 和该领域的其他科学家有可能革新我们对大脑的理解。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;毕竟，人类大脑是宇宙中已知的最为复杂的东西，人类几乎搞不懂它。Gallant 实验室的雄心——让神经科学摆脱不成熟阶段——：或许可以打造出一台为我们解读大脑的机器。如果可以解码极端复杂的大脑模式，就有可能找出修复大脑的办法（当大脑深受疾病之苦时）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;MRI——我们用来窥探和分析大脑功能及其解剖学的工具——诞生于上世纪九十年代，效果透光不均匀。为了让效果透视化，fMRI 能够观察到的脑部活动最小单元到了体素（voxel）层面。这些体素通常小于 1 立方毫米。而一个体素中可能有 10 万个神经元。德克萨斯大学的神经科学家 Tal Yarkoni 告诉我，fMRI「就像飞过城市，找到哪里亮着灯。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.83" data-s="300,640" data-type="jpeg" data-w="400" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsq8ibeK6bhdKeb000yQBdvh345pmJdAOK0caZpZYVDBPMIWsyQ4BiaLQA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;传统的 fMRI 成像可以呈现出对某个行为至关重要的广阔区域在哪里——比如，你可以看到大脑哪里处理负面情绪或者当我们看到熟悉面孔时，哪里会亮起来。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但是，你无法确切知道这个区域在行为中扮演什么样的角色，或者其他不那么活跃的区域是否也扮演着重要作用。大脑不是乐高玩具，每块玩具都有着特定的功能。大脑是一张活动之网。Gallant 说，「每个大脑区域会有 50% 的可能与大脑其他区域连接起来。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这就是为什么简单的实验——识别「hunger（饥饿）」或者「vigilance(警觉）」所在大脑区域——无法真的得出让人满意的答案。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;美国国家精神健康研究院（National Institute of Mental Health）fMRI 部门负责人 Peter Bandettini 告诉我，「过去十五年中，我们一直研究这些一团一团东西的活动。结果，每一团中细微差别、每一次波动的细微差别都包含着大脑运动的信息，而我们无法真正挖掘出来。这也是我们需要这些机器学习技术的原因。我们可以看到一团团的东西，却识别不出模式，因为这些模式太复杂了。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;举个例子。大脑如何处理语言？传统的看法是活动发生在左半球的两个特定区域——布洛卡区和威尔尼克区域——这是语言活动的中心区域。如果它们受损，人就会失去语言能力。不过，Gallant 实验室的博士后 Alex Huth 最近发现，这个观点太过简单。他想知道整个大脑是否都与语言理解相关。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;实验中，他请几个被试听两个小时的故事节目 The Moth，与此同时，同事们用 fMRI 扫描仪记录被试大脑活动。他们想要将大脑不同区域与所听到的单个语词关联起来。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;实验产生了很多数据，人力很难处理。Gallant 说。但是，可以训练计算机程序寻找数据中的模式。因此，Huth 设计了可以揭示出语义地图的程序，地图显示出每个语词所在大脑区域。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="http://v.qq.com/iframe/preview.html?vid=q0361v065me&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;「Alex 的研究表明，语义理解需要动用大脑的大部分区域，」Gallant 说道。Alex 同时也展示了意义相似的单词（如 poodle 和 dog）在大脑中的刺激到的位置彼此靠近。&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这个研究的意义何在？在科学里，预测就是力量。如果科学家可以预测让人眼花缭乱的大脑活动是如何进行语言理解的，他们就可以受此启发构建更高效的模型。而一旦新的模型被建立起来，他们就可以更好地认识变量改动后的情况——大脑出现病变时。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;什么是机器学习？&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;「机器学习」是一个内容广泛的概念，包含了各类算法与系统。机器学习目前已经被大量应用到消费级产品中去了——例如让计算设备学会识别图片中的物体，其准确程度堪比人类。机器学习的一个分支「深度学习」是最近最为引人注目的词汇，这种技术已经让谷歌的翻译服务从生硬的单词翻译进化到可以把海明威的著作翻译成各国语言，同时保留原作风格的水平。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在最基本的层面上看，机器学习程序需要先使用数据集进行「训练」。在训练中，程序会在数据中寻找模式。通常来说，训练越多的数据，系统就会有更好的表现。一旦经过训练，在遇到同类型的数据之后，系统就可以展开预测了。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;最常见的例子就是电子邮件中的垃圾邮件过滤程序。机器学习通过扫描足够数量的垃圾邮件，学习其中内容的特性，从而在收到新的邮件时帮你进行分析和拦截。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;机器学习可以是非常简单的程序，仅仅进行数学回归运算（这只是中学数学知识，比如从一些已知条件中算出一条线段的斜率）；也可以是非常复杂的系统，就像谷歌 DeepMind，经过了数以百万条数据的训练，从而在围棋上打败人类世界冠军（围棋的棋局变化数量超过了宇宙中所有原子的数量）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;神经科学家正在使用机器学习进行着一些研究。如编码与解码。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;通过「编码」，研究人员试图使用机器学习来预测不同刺激在大脑中造成的影响。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;「解码」则与之相反，通过观察大脑活动来反推受试者正在思考什么。（注：神经科学家可以使用不同大脑扫描方式为机器学习提供数据，除了 fMRI 以外还有 EEG 和 MEG 等）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;俄勒冈大学的神经科学家 Brice Kuhl 最近使用 fMRI 数据解码，重建了受实验者眼睛里看到的内容。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Kuhl 通过核磁共振成像研究的脑区一直被认为与人类记忆密切相关。「这个脑区的活动显示了你所看到物体的细节——或许仅仅是（点亮），因为它是你非常确定的记忆。」Kuhl 说道。机器学习程序可以从这个脑区的活动图像中预测被试者看到的人的面部特征，这表明这个位置就是「你看到的细节」被处理的地方。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.5317258883248731" data-s="300,640" data-type="png" data-w="788" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsVaxsosjysDr7FJeYE09sgbc7cZcibNBk8RfroMk62IngJCTrNdlQuiaQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;第一行是 Kuhl 研究中的原始面孔；第二行是基于大脑的两个不同区域中的活动，机器学习进行的猜测，重建远非完美，但它们表现出了原面部的一些基本细节，如性别、肤色和表情&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;同样，Gallant 有关艺术作品的实验揭示了一个关于心灵的小秘密：当我们看到相同物体时，我们会激活大脑中相同的区域。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;所有接受采访的神经科学家们都表示机器学习并没有彻底改变他们的领域。究其原因——没有足够的数据。扫描大脑活动需要花费大量时间，而且价格昂贵。同时，一项研究通常会招募几十名受试者，而不会有几百人。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;「在 20 世纪 90 年代，神经影像学刚刚起飞时，人们关注类层面（category level）的表征——大脑的哪个部分处理人的面孔（而不是房子和物体），这是大尺度的问题，」匹茨堡大学的神经科学研究院 Avniel Ghuman 解释道。「现在我们可以研究很多细节上的问题，比如：这让他/她回忆起了十分钟前想到的同一件事吗？」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;「这种进步是革命性的。」Ghuman 说道。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;神经科学家希望机器学习可以帮助诊断和治疗精神障碍&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;目前，精神科医生还不能通过让病人接受 fMRI 扫描来确定他/她是否患有精神疾病（如精神分裂症）。他们仍然不得不依靠在临床上与患者进行对话（毫无疑问，这种方式获得的信息具有很大价值）。但机器学习带来的新型诊断方法将会让疾病的诊断更加准确，这无疑会给医疗领域带来新的进步。为了做到这一点，美国国家精神健康研究院（NIMH）的 Bandettini 表示，神经科学家们需要获得 10,000 份以上 fMRI 扫描结果的数据集。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;机器学习程序可以从精神病人的大脑活动图像中寻找模式，学会进行识别。「随后你可以开始把它应用在临床上，扫描一个病人然后说：基于容量为 10,000 的数据集的训练，我们现在可以作出初步诊断，此人患有精神分裂症。」Bandettini 表示，现在，这些研究仍然处于初级阶段，新的突破还没有出现。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但是，如果我们理解了大脑中各区域组成的网络是如何工作的，这些方向很快就会转化为成果。「在未来，我们也许能设计复杂的干预措施在大脑出现病变时进行治疗，」MIT 计算神经科学家 Dan Yamins 说道。「也许我们可以把某种植入物放进大脑，用来治疗阿尔茨海默病，或者也可以治疗帕金森症。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;机器学习还可以帮助精神科医生预测不同患者的大脑会如何对抑郁症的药物治疗产生反应。「现在的精神病医生不得不猜测，从诊断角度来看，哪种药物可能是有效的，」Yamin 说道。「因为有时症状并不能说明大脑中发生的一切。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但 Yamin 同时指出，这些愿景可能很长一段时间都无法实现。很多科学家们现在正在思考这些问题。NeuroImage 期刊曾出版过一个专刊登载预测个体大脑差异和神经影像学诊断的论文。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这是非常重要的研究方向，因为当涉及到医疗领域时，预测为治疗和预防疾病带来了新思路。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;机器学习可以预测癫痫发作&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;癫痫病的患者永远无法得知自己将在何时发病。「这对你的生活来说是致命的——你不能开车，不能正常生活，因为你随时有可能发病，」国立卫生研究院的神经科学家 Christian Meisel 说道。「如果拥有一个预警系统，一切都将会不同。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;目前人们对癫痫病的治疗方式也不甚完美。一些患者不得不 24 个小时不断服用抗惊厥药物，而这些药物具有严重的副作用。而对于 20%-30% 的患者来说，没有任何药物对他们有效。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;用预测来改变这一切。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果癫痫患者知道癫痫发作即将来临，他们至少可以提前找到一个安全的地方。预测还可以改变治疗方式：提前警告可以告诉患者快速服用癫痫药物，或发送电信号以阻止其即将出现的发作。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这是一个 EEG——脑电图图像——Meisel 分享了一个癫痫病人的例子。「现在是没有癫痫发作的情况，」Meisel 说道。「问题是，这种情形距离发病有一小时还是四个多小时？」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.4542124542124542" data-s="300,640" data-type="png" data-w="1092" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs0a0Tia2FicBlngM7wIajU4bPFa4icsxYUy0E3O6w112EPpGODKm8iaWflA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;对于临床医生来说，预测是非常困难的，他说，甚至是不可能的。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但关于一场即将发作的癫痫的信息可能隐藏得非常微妙。为了测试这种可能性，Meisel 的实验室最近参加了一个由网络上的数据科学社区中心 Kaggle 主办的比赛。Kaggle 提供了三位癫痫患者的几个月和几年的 EEG 记录。Meisel 使用了深度学习来分析这些数据并寻找其中的模式。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;根据癫痫的前奏的 EEG 扫描来预测癫痫发作，这能够做到多好？「如果你有一个可以预测一切的完美系统，你得 1 分。」Meisel 说，「如果你只有一个抛硬币的随机系统，你得分 0.5。而我们现在的得分是 0.8。也就是说我们的系统现在并不能做到完美预测，但却比随机好很多。」（这听起来似乎不错，但目前这个方法更多还是理论上的，并不实用。这些患者是通过颅内 EEG 监测的，这是一种侵入式操作。）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Meisel 是一位神经学理论学家，绘制了癫痫发作病症如何从小型的神经活动发展成完全的衰竭型行为的模型。他说，机器学习是帮助他改善其理论的有用工具。他可以将自己的理论引入到机器学习模型中，观察它是否使得系统更具预测性。「如果有效，那我的理论就是正确的。」他说。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;从机器学习到真正有用，神经科学将需要变成一种大数据科学。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.76171875" data-s="300,640" data-type="jpeg" data-w="1280" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsu3tBtCia6XYQNWftCZZ3xasz6K6cABpwvceIOpYCMTgfvIjwqyuy52A/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;机器学习并不能解决神经科学领域内的所有大问题。它可能会受限于来自 fMRI 和其它脑扫描技术的数据的质量。（最好的也就是 fMRI 绘制出的大脑的模糊影像。）「就算我们有无限的成像数据，你也不能得到完美的预测，因为这些成像流程本身是非常不完美的。」计算机科学家 Gael Varoquaux 如是说，他已经开发出了一款用于神经科学的机器学习工具包。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但至少我访问过的神经科学家都对机器学习感到兴奋，因为机器学习有利于实现更干净的科学（cleaner science）。机器学习解决了所谓的「多重比较问题（multiple comparison problem）」，其中研究者的工作本质上是在他们的数据中挖掘出统计学上显著的结果（只要有足够的脑扫描数据，某些地方的一些区域就会「点亮」）。使用机器学习，不管你对大脑行为的预测是否正确，Varoquanx 说：「预测是你可以控制的东西」。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;大数据的方法也意味着神经科学家可以在实验室之外开始自己的行为研究。「我们所有的关于大脑活动方式的传统模型都基于那些人工设置的实验环境」，Ghuman 说，「当涉及到真实世界环境时，我们并不完全清楚它是否还是有效。」如果我们有了关于大脑活动（也许来自可穿戴的 EEG 监测器）和行为的足够数据，机器学习就可以开始寻找将这两者联系起来的模式，而不再需要认为设置的实验。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在神经科学领域使用深度学习还有最后一个可能性，这听起来很科幻：我们在大脑上使用机器学习来开发更好的机器学习程序。过去十年机器学习领域内最大的进步是被称为「卷积神经网络」的思想。谷歌就是用这种技术来识别照片中的物体的。这些神经网络基于神经科学的理论。所以，随着机器学习在理解大脑上做得越来越好，机器学习本身也可以从中学习技巧，从而变得更加聪明。经过这样改进的机器学习程序又可以继续研究大脑，让我们可以更进一步地了解更多神经科学。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;（研究人员也可以从机器学习项目中吸取洞见，比如训练机器学习重现视觉这样的人类行为的项目。可能在学习这些行为的过程中，这些项目能重现大脑做出行为的方式。）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Varoquanx 说，「我不想让人们认为我们突然开始研发大脑读取设备，事实不是这样。我们希望得到更丰富的计算模型，从而更好地理解大脑，这才是我们想要做的。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;原文链接：http://www.vox.com/science-and-health/2016/12/29/13967966/machine-learning-neuroscience&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="min-height: 1em; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="text-align: justify; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;</description><guid isPermaLink="false">http://chuansong.me/n/1417253342275</guid></item><item><title>业界 | 机器学习硬件展望：专用化是大势所趋</title><link>http://chuansong.me/n/1417253442260</link><description>&lt;div class="rich_media_content " id="js_content"&gt;
&lt;section style="white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 1em; margin-top: -1.2em; min-height: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; background-color: rgb(117, 117, 118); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自IEEE Spectrum&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px;"&gt;&lt;strong&gt;参与：吴攀、朱思颖&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 14px; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;从微小器件到海量数据中心，格外强劲的硬件将能为深度学习领域内的一切提供助力。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2016 年 3 月份，谷歌 DeepMind 的计算机在多轮围棋比赛中击败了世界围棋冠军李世乭。这一事件标志着人工智能领域内的一个新里程碑。获胜的 AlphaGo 借力于现在为大家所熟知的深度学习——一种人工神经网络；在这种神经网络里有很多计算处理层，可以用来自动寻找问题的解决方案。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;那时候人们还不知道谷歌正在悄然开发为这一胜利提供助力的秘密武器——一种专用硬件，在谷歌用于击败世界冠军李世乭的计算机里已有这种特殊硬件。这种硬件被谷歌称为张量处理单元（TPU/Tensor Processing Unit）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;谷歌的一位硬件工程师 Norm Jouppi 在这场围棋大战的两个月后宣布了张量处理单元的存在，并解释说谷歌的数据中心已经使用这些新型加速器一年多了。谷歌还没有公布这些集成板上到底有什么奥妙，但毫无疑问的是，这代表着加速深度学习计算上的一个日益流行的策略：使用专用集成电路（ASIC）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="1" data-s="300,640" data-type="jpeg" data-w="220" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs73KzxfB6WXlXCtBO5xWbtLBiccaloFXAV5jy8PKrd4rEicrk1mOQEuyQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px; text-align: justify;"&gt;来自深度学习软件的收入很快就将超过十亿美元（单位：十亿美元；来源： Tractica）&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;企业（主要是微软）追求的另一个战术是使用现场可编程门阵列（FPGA），其有可重配置的优势，可以根据计算需求进行修改。而更常见的方法则是使用图形处理单元（GPU），这种计算设备可以并行地同时执行大量数学运算。最知名的 GPU 提供商英伟达（NVIDIA）近段时间以来的股价飞涨也正是得益于此。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;事实上，GPU 在 2009 年的时候就已经在驱动人工神经网络了，那时候斯坦大学的一些研究者证明这种硬件使得深度神经网络的训练时间很适宜。（参阅论文《Large-scale Deep Unsupervised Learning using Graphics Processors》）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;「今天所有人都在做深度学习，」斯坦福大学 Concurrent VLSI Architecture 研究组的领导者兼英伟达首席科学家 William Dally 说。他说这从他的角度来看是不足为奇的。「GPU 几乎和你想象的一样美好。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Dally 解释说有三个独立的领域需要考虑。第一是他所说的「数据中心中的训练」。他认为任何深度学习系统的第一步都是：调节神经元之间大约数百万个连接以使网络能够完成分配给它的任务。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;已被英特尔收购的公司 Nervana Systems 在这种任务的硬件开发上取得了领先。Nervana 计算机科学家 Scott Leishman 表示 Nervana Engine 是一款 ASIC 的深度学习加速器，其将在 2017 年初期到中期的时候投入生产。Leishman 指出另一个计算密集型任务——比特币挖矿（bitcoin mining），就曾经从 CPU 实现转向 GPU，然后转向 FPGA 并最终转向了 ASIC，因为定制的硬件能够实现更优的能量效率。他说：「我认为同样的情况正在深度学习领域发生。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Dally 说，深度学习硬件的第二个任务（大为异于第一个任务）是「数据中心中的推理」。「推理（inference）」这个词在这里的意思是：用于之前任务的已训练的基于云的人工神经网络在同样的任务上能进行持续运算。谷歌的神经网络每天都要执行天文数字级别的推理计算，以帮助用户分类图片、翻译语言和识别口语等等。尽管外界还不能百分之百确定，但可以推理谷歌的张量处理单元应该在为这些计算提供助力。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.9709677419354839" data-s="300,640" data-type="jpeg" data-w="620" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsVicIm1ZCTsQURIvkF8s1DystOvpjXicgePgWamf7vKumVB3uoTP5lnIA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;加满油门：谷歌的 TPU 正在该公司的服务器里加速深度学习计算&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;训练和推理常常需要运用不同的技能设置。通常对训练的设置上，机器必须能够实施精确度相对较高的计算，常使用 32 位的浮点计算。对于推理，则可以牺牲精确度以获取更快的速度和更低的功耗。「这是研究领域里一个很活跃的区域，」Leishman 说道。「你能达到的最低限度是多少？」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;虽然 Dally 谢绝泄露英伟达的特别计划，但他指出英伟达的 GPU 正在完成升级。英伟达的早期版本——Maxwell 的架构能够进行双精度（64 位）和单精度（32 位）的计算，而目前的 Pascal 架构则增加了处理 16 位运算的能力，支持双倍输入且效率也是之前单精度计算的两倍。所以不难想象英伟达最终将会推出能进行 8 位运算的 GPU，这样的 GPU 将是在云端进行推理运算的理想硬件，因为对云端推理来说能源效率是控制成本的关键因素。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Dally 补充说：「三个支撑深度学习关键任务的最后一个任务就是在嵌入式设备里进行推理，」比如智能手机、相机和平板电脑。对于这些应用，关键是实现低能耗的专用集成电路（ASIC）。在即将来到的一年，深度学习软件将会越来越多的实现手机端应用，比如目前已有的手机端应用——恶意软件检测以及图片中的文字翻译。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;除此之外，无人机生产商大疆（DJI）已经开始在其幽灵 4（Phantom 4）无人机中使用与专用集成电路的深度学习相类似的器件，大疆所使用的器件是一个由加州厂商 Movidius 制造的特殊视觉处理芯片，这个芯片用来识别障碍物。（Movidius 同时也是英特尔最近收购的另一家神经网络相关的公司）。与此同时高通（Qualcomm）在其 Snapdragon 820 处理器里放置了一个特殊的电路系统来更好地执行深度学习运算。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;虽然目前有很多因素促使硬件设计来加速深度神经网络的计算，但巨大的风险依然并存：如果神经网络的进步太快，所设计来运行过往的神经网络的芯片在出厂时就会过时。「算法正以非常快的速度改变，」Dally 说。「所有从事构建这些硬件的人都在试图赢得这场赌注。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;原文链接：http://spectrum.ieee.org/computing/hardware/expect-deeper-and-cheaper-machine-learning?utm_source=feedburner&amp;amp;utm;_medium=feed&amp;amp;utm;_campaign=Feed%3A+IeeeSpectrum&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="min-height: 1em; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="text-align: justify; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/div&gt;</description><guid isPermaLink="false">http://chuansong.me/n/1417253442260</guid></item><item><title>资源 | 深度学习资料大全：从基础到各种网络模型</title><link>http://chuansong.me/n/1417253542266</link><description>&lt;div class="rich_media_content " id="js_content"&gt;
&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 1em; margin-top: -1.2em; min-height: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; background-color: rgb(117, 117, 118); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自Yerevann&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#7f7f7f"&gt;&lt;span style="font-size: 12px;"&gt;&lt;strong&gt;参与：Jane W、Rick、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;深度学习是发展迅速的一个计算机科学和数学交叉的领域。它是更宽泛的机器学习领域一个相对新的分支。机器学习的目的是教计算机完成基于给定数据的各种任务。本教程是为那些知道一些数学，又懂一些编程语言，并想研究深度学习的人准备的。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;文中的链接请点击网址：http://yerevann.com/a-guide-to-deep-learning/&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;预备知识&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.24111675126903553" data-s="300,640" data-type="png" data-w="2364" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsvTN9kEyTjJh7icleO3Z8J7B93tZFuh7PAeq2VSkib2kdicQVEzNdFFvVA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你必须有大学数学知识。你可以在深度学习这本书的前几章中回顾这些概念：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习，第 2 章：线性代数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习，第 3 章：概率与信息论&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习，第 4 章：数值计算&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你必须知道编程知识以便开发和测试深度学习模型。我们建议使用 Python 进行机器学习。这里需要用到科学计算的 NumPy / SciPy 库。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;斯坦福 CS231n 课程，Justin Johnson 的 Python / NumPy / SciPy / Matplotlib 教程 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Scipy 讲义——更详细地描述了常用库，并介绍更多高级主题 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当你满足了这些预备条件时，我们有四个备选建议用来学习深度学习。你可以选择下列选项中的任何一个或几个。星星数量表示困难程度。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio="0.4853195164075993" data-s="300,640" data-type="png" data-w="1158" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsx3GrPkTWRBRMRWQpNKSCAnzia4zasJrkK2KU3VLMBZPU3rjQjYiaSIMw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Hugo Larochelle 在 YouTube 上的课程视频（Hugo Larochelle's video course）。虽然视频是在 2013 年录制的，但大部分内容仍然很新。视频详细地解释了神经网络背后的数学知识。附带幻灯片和相关材料。★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;斯坦福 CS231n 课程（卷积神经网络的视觉识别/ Convolutional Neural Networks for Visual Recognition）由李飞飞、Andrej Karpathy 和 Justin Johnson 教课。本课程侧重于图像处理，但涵盖了深度学习中的大多数重要概念。附带视频（2016 年）和讲义。★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Michael Nielsen 的网络书籍《神经网络和深度学习》（Neural Networks and Deep Learning）是研究神经网络的最容易入门的书籍。它没有涵盖所有重要的主题，但包含直观解释和基本概念的代码实现。★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Ian Goodfellow、Yoshua Bengio 和 Aaron Courville 的书《深度学习》（Deep Learning），是研究深度学习最全面的资源。它比所有其它课程涵盖了更多的内容。★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;有许多软件框架为机器学习和深度学习提供了必要的函数、类和模块。我们建议在研究的早期阶段不要使用这些框架，而是从头开始实现基本算法。并且大多数课程都能足够详细地描述算法背后的数学，因而这些算法可以很容易从头实现。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Jupyter notebook 软件可以方便地交互编译 Python 代码。软件能很好地与流行的可视化库 matplotlib 集成。我们建议在这样的环境中实现算法。★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;机器学习基础&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;机器学习是基于数据训练计算机的一门艺术和科学。它是计算机科学和数学交叉的相对确定的领域，而深度学习只是它的一个很小的子领域。机器学习的概念和工具对于理解深度学习非常重要。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.5621716287215411" data-s="300,640" data-type="png" data-w="1142" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsPibrxqjV3SzDBU3RCicO9HNHDkGEqMofxntLGFoaUrroOfgSyZMibhwLQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;视觉化介绍机器学习（Visual introduction to machine learning）——决策树 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Coursera 上最受欢迎的课程，Andrew Ng 的机器学习课程（Andrew Ng's course on machine learning）★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Larochelle 的课程，没有单独的通用机器学习的介绍性讲座，但是定义和解释了所有必要的概念。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;1. 训练和测试模型（K 最近邻/kNN）★★&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2. 线性分类（支持向量机/SVM）★★&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;3. 优化（随机梯度下降/ stochastic gradient descent）★★&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;5. 机器学习基础 ★★★&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;可视化的主成分分析讲解 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如何有效地用 t-SNE 算法 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;大多数流行的机器学习算法都是在 Python 库 Scikit-learn 中实现的。从头开始实现这些算法助于理解机器学习的原理。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Python 的实用机器学习教程（Practical Machine Learning Tutorial with Python），包含了线性回归、kNN 和支持向量机。首先介绍了如何从 scikit-learn 调用算法，然后从头实现算法。★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Coursera 上 Andrew Ng 的课程的许多作业使用 Octave 语言。也可以在 Python 中实现这些算法。★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;神经网络基础&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;神经网络是强大的机器学习算法。它们构成了深度学习的基础。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio="0.7101967799642218" data-s="300,640" data-type="png" data-w="1118" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsicVIuxtkMzqvFRMYqYDBJW2G5CrCmc52UCsw6ZQmmzU9sqQVQQz3xmg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一个交互可视化的教程，介绍了神经网络的基础——显示简单的神经网络如何做线性回归 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;1. 前馈神经网络（feedforward neural network）★★&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2. 训练神经网络（直到 2.7）★★&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;4. 反向传播（backpropagation）★★&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;5. 神经网络的架构 ★★&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;1. 使用神经网络来识别手写数字 ★&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2. 反向传播算法的原理 ★&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;4. 神经网络以计算任何函数的可视化证明 ★&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;6. 深度前馈网络 ★★★&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;理解为什么从头开始实现反向传播算法很重要 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;计算图（computational graph）中的微积分：反向传播 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;玩转神经网络！★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;尝试从头实现单层神经网络，包括训练过程。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;只用 Python / NumPy 实现 softmax 分类器以及一个简单的神经网络——用 Jupyter notebook ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Andrej Karpathy 的神经网络黑客教程讲述了如何在 Javascript 中实现反向传播。★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在 Python 中从头开始实现一个神经网络 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;改进神经网络的学习方式&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;训练神经网络并不容易。有时根本不能学习（欠拟合/ underfitting），而有时能准确地学习你给算法的数据，但是算法学到的「知识」不能泛化到新的、没见过的数据（过拟合/ overfitting）。有许多方法来解决这些问题。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.6591337099811676" data-s="300,640" data-type="png" data-w="1062" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsy1Gbsh7e6Xicmulhxad0iax5p7sEAibQUcWlrUHy4qVVBZicZVADdqchJg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2.8-2.11. 正则化（regularization），初始化参数（parameter initialization）等 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;7.5. Dropout 方法 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;6（前半章）. 设置数据和损失函数（loss）★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;3. 改进神经网络学习的方式 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;5. 为什么深度神经网络难以训练？★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;7. 深度学习的正规化 ★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;8. 优化训练的深度模型 ★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;11. 实用方法 ★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;MNIST 上的 ConvNetJS Trainer 演示——不同的优化算法性能的可视化 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;梯度下降优化算法的概述 ★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;神经网络、流形（Manifold）和拓扑（Topology）★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;有许多框架提供标准算法，并针对现代硬件的良好性能进行了优化。这些框架中的大多数提供 Python 接口，除了著名的 Torch 是个例外（其需要 Lua）。一旦你知道如何实现基本的学习算法，现在是选择一个建模框架的时候了。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio="1.0392609699769053" data-s="300,640" data-type="png" data-w="866" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs3h6UcIvWgX9Vb3VBdvUXM3Ptqbm9F80cnRCUaV3tAy54DSNiag3E3Yg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Theano 提供用于构建各种神经网络的低层级原生库（low-level primitives）。它由蒙特利尔大学（University of Montreal）的机器学习团队维护。参见：用 Theano 和 GPU 加速你的神经网络——用 Jupyter notebook ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow 是另一个低层级框架。它的架构类似于 Theano。它由谷歌大脑团队维护。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Torch 是使用 Lua 语言的流行框架。主要的缺点是 Lua 的社区不像 Python 的那么大。Torch 主要由 Facebook 和 Twitter 维护。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;还有更高层级的框架，它们运行在这些低层级框架之上：&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Lasagna 是一个建立在 Theano 之上的更高级框架。它提供了简单的函数，从而可以用少量代码创建大型网络。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Keras 是一个更高级框架，建立在 Theano 或 TensorFlow 之上。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果你需要更多关于选择框架的建议，请参见斯坦福大学 CS231n 课程的第 12 讲。★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;卷积神经网络（Convolutional neural networks）&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;卷积神经网络（「CNN」）是一种特殊的神经网络，它使用了一些妙技来更快、更好地学习。ConvNets 从根本上变革了计算机视觉，并且也被大量应用于语音识别和文本分类任务中。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.7928436911487758" data-s="300,640" data-type="png" data-w="1062" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsJzibXkAB8k6LEE0XNqhlS81Vhsf1RxeCFxwYBbggS7Kcm3h7hdFn40Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;9. 计算机视觉（至 9.9）★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;6（下半部）.ConvNets 介绍 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;7. 卷积神经网络 ★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;8. 定位与检测 ★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;9. Visualization、 Deep Dream、Neural Style、对抗样本（adversarial examples）★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;13. 图像分割（至 38:00）包括 upconvolutions ★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;6. 深度学习 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;9. 卷积网络 ★★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;图像核函数（Image Kernel）的视觉阐述——展示卷积过滤器（Convolutional Filters，也称为图像核函数）如何转换图像 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Conv Nets：以模块化的视角 ★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;理解卷积 ★★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;理解自然语言处理（NLP）中的卷积神经网络 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;每一个重要框架都应用了卷积网络。通常理解用更高级库编写出来的代码更容易。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="1.1921296296296295" data-s="300,640" data-type="png" data-w="864" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsiaxoqhUFf75K2H7Yc10IAKXI3RPpHXmVcqWv2DBnqVuJ4DFnvibpKsibg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Theano：卷积神经网络（LeNet）★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;使用 Lasagne 来训练深度神经网络 ★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;检测糖尿病视网膜病变——出自 Kaggle 糖尿病视网膜病变检测竞赛最佳选手的一篇博文。包含一个绝佳的数据增强案例。★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;使用深度学习进行的露脊鲸面部识别——作者在定位和分类过程中使用了不同的 ConvNets。内附代码及模型。★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;TensorFlow：在 CIFAR-10 数据集上进行图像识别的卷积神经网络 ★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在 TensorFlow 中使用一个卷积神经网络进行文本分类 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习在 TensorFlow 中的实施 ★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Torch 中的 CIFAR-10 准确性为 92.45%——在 Torch 中实现带有批量归一化层（batch normalization layers）的 VGG-Net 网络 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;残差网络（Residual Net）的训练与考察——残差网络在图像分类方面表现不错。来自 Facebook 和 CornellTech 的两位研究人员在 Torch 中采用了这种网络 ★★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;ConvNets 实践——使用卷积网络方面的许多实用技巧包括：数据增强、迁移学习、卷积运算的快速实现 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;循环神经网络（Recurrent neural networks）&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;循环神经网络（RNN）是与序列一起使用的。通常用于语句分类（比如情感分析）和语音识别，但也用于文本生成，甚至图像生成。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio="0.6483931947069943" data-s="300,640" data-type="png" data-w="1058" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs5tI6rWdG7Zib94Og1yU18VolpLazwOFHDzJQMrj1asAImM6rHKPCOhA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;循环神经网络的合理有效性——描述了 RNN 如何生成文本、数学论文和 C++ 代码 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Hugo Larochelle 的课程并不涉及循环神经网络（即使它涵盖了循环神经网络应用方面的许多话题）。我们推荐你补上 Nando de Freitas 的《Recurrent Neural Nets and LSTMs》课程 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt; 10. 循环神经网络、图像字幕、LSTM ★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;13.Soft Attention（38:00 起）★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Michael Nielsen 的书最后一节是卷积网络。深度神经网络的其他方法（Other approaches to deep neural nets）一节只是简要回顾了简单循环网络和 LSTM。★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;10. 序列建模（Sequence Modeling）：循环和递归网络（Recurrent and Recursive Nets）★★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;斯坦福大学 Richard Socher 教授的 CS224d(2016)《循环神经网络（Recurrent Neural Networks）》课程★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt; 了解 LSTM 网络 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;循环神经网络也被用在了每一个现代框架中。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.9193548387096774" data-s="300,640" data-type="png" data-w="868" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsKkYYxt70tG0iavEK2729p2XVbBTBufjbfPiaU6QTg0MmrL7cOgN0gcbw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Theano：有单词嵌入的循环神经网络 ★★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Theano：用于情感分析的 LSTM 网络★★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;使用 Python、NumPy 和 Theano 实现循环神经网络 ★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;karpathy 的 char-rnn 代码的 Lasagne 实现 ★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在 Lasagne 中结合卷积神经网络和循环神经网络用于口语识别 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在 Lasagne 中采用 LSTM 网络进行自动音译 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Tensorflow：用于自然语言建模的循环神经网络 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Tensorflow 中的循环神经网络 ★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;理解并实现 Deepmind 的 DRAW 模型 ★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt; LSTM 的实现说明 ★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;karpathy 的 char-rnn 代码的 Torch 实现 ★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;自编码器（Autoencoders）&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;自编码器是为无监督学习（例如数据未标记的情况）而设计的神经网络。可用它进行降维、预训练其他神经网络及数据生成等。以下资源还包括自编码器与图形模型的有趣混合体，称为变分自编码器（variational autoencoders），不过其数学基础是下一节的内容。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio="0.38301886792452833" data-s="300,640" data-type="png" data-w="1060" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs4HUKQsZXLVpkO5FFlzYcpHffpGSVv6gNErAqicSwZDgichVqhQ080iaNQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;6. 自编码器（Autoencoder）★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;7.6. 深度自编码器（Deep Autoencoder）★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;14. 视频与无监督学习（32:29 起）——此视频还涉及一个令人兴奋的话题：生成对抗网络（Generative Adversarial Networks/GAN）。★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;14. 自编码器（Autoencoders）★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;ConvNetJS 去噪自编码器演示 ★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;变分自编码器与图像生成中的 Karol Gregor ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;大多数的自编码器都很容易实现。我们建议你浏览完整案例前自己先试着实现一下。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.4013761467889908" data-s="300,640" data-type="png" data-w="872" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs4hfAoSBFVoZTvCLsCq2GM9ibVvtFym06VChgIuEWg63tQGRY5f5XopQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Theano：去噪自编码器 ★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;使用堆栈式自编码器（stacked autoencoders）深入研究 Tensorflow ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Tensorflow 中的变分自编码器 ★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在 ImageNet 上使用 Torch 7 训练自编码器 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在 Keras 中构建自编码器 ★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;概率图模型（Probabilistic graphical models/PGMs）&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;概率图模型（PGM）在统计学与机器学习的交叉领域形成一个独立的分支。一般说来关于 PGM 的书籍和课程有很多。这里我们提出的是：在深度学习中如何应用这些模型。Hugo Larochelle 的课程介绍了几个著名的模型，而《Deep Learning》一书则用了四章（16-19）来阐述该理论，并在最后一章介绍了十几种模型。这些课题都需要大量的数学知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.8914285714285715" data-s="300,640" data-type="png" data-w="1050" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsibxSNWFXePtROM0C3vyn2o6ODTFX4bHTf8tmMctlfbDyLkklIKnORJQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;3. 条件随机场（Conditional Random Fields/CRF）★★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;4. 训练条件随机场 ★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt; 5. 受限玻尔兹曼机（Restricted Boltzmann Machine/RBM）★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;7.7-7.9. 深度信念网络（Deep Belief Network/DBN）★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;9.10. 卷积受限玻尔兹曼机 ★★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;13. 金融线性模型（Linear Factor Models）——概率模型的第一步 ★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;16. 深度学习的结构化概率模型 ★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt; 17. 蒙特卡洛（Monte Carlo）方法 ★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;18. 对抗配分函数（Confronting the Partition Function）★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;19. 近似推断（Approximate Inference）★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;20. 深度生成模型（Deep Generative Models）——包括玻尔兹曼机（RBM、DBN 等）、变分自编码器（variational autoencoders）、生成对抗网络、自回归模型（Autoregressive Models）等 ★★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;生成模型——变分自编码器、生成对抗网络及其 OpenAI 改进方面的一篇博文。★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;神经网络园（The Neural Network Zoo）试图使用一个单一方案组织大量架构。★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;更高层次的框架（Lasagne、Keras）不执行图形模型。但有很多为 Theano、Tensorflow 和 Torch 而编写的代码。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.49311926605504586" data-s="300,640" data-type="png" data-w="872" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsHCNEGickNzyBib0CicyrxjQGRJv2bXjNCRILeT2jgrtt9icKWhNCcPkx7A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Theano 中的受限玻尔兹曼机 ★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Theano 中的深度信念网络 ★★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;由特征向量生成大图像——结合运用变分自编码器（variational autoencoders）与生成对抗网络。★★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在 TensorFlow 中使用深度学习进行图像修复——生成对抗网络的另一个应用。★★★ &lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;使用 Torch 的面部生成——生成对抗网络的 Torch 实现 ★★&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;前沿&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习是一个非常活跃的科学研究领域。要想跟上顶尖的科研进程，就必须阅读新的论文并跟上重要的会议。通常每个新思想都是在 arXiv.org 的预印本论文上发表。然后其中一些提交给会议并进行同行评议。最好的那些会在会议上被提出并发表在期刊上。如果该作者不发布其模型的代码，许多人会试图实现它们并将其放在 GitHub 上。这得需要 1、2 年的时间，合理解释其思想和实现过程的高品质技术博客、教程和视频才会出现在网络上。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.16302521008403362" data-s="300,640" data-type="png" data-w="1190" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsHmO9kLfTDkfRibqpdibuIapxe7IBhrS1O0ahsj2kxQdicBOq4AlbDOMRQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习论文阅读路线图包含一长串的重要文件。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Arxiv Sanity Preserver 的用户界面在 arXiv 上浏览论文的效果不错。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Videolectures.net 包含许多高级课题相关的视频。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;/r/MachineLearning 是一个非常活跃的 Reddit 板块。所有新的重要论文都会在那里进行讨论。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="min-height: 1em; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="text-align: justify; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/div&gt;</description><guid isPermaLink="false">http://chuansong.me/n/1417253542266</guid></item><item><title>业界 | 亚马逊新专利：空中无人机堡垒</title><link>http://chuansong.me/n/1417253642251</link><description>&lt;div class="rich_media_content " id="js_content"&gt;
&lt;section style="white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 1em; margin-top: -1.2em; min-height: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; background-color: rgb(117, 117, 118); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自CB Insights&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 16px; margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#7f7f7f"&gt;&lt;span style="font-size: 12px;"&gt;&lt;strong&gt;参与：曹瑞、李亚洲&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;亚马逊一直致力于无人机送货项目的研究，但一些新专利的出现说明亚马逊的研究并不是疯狂的想法。CB Insights 的分析师 Zoe Leavitt 发现亚马逊最近申请了「使用无人机送货的航空物流中心」的专利——也就是说，要打造空中航母来充当配送中心，利用无人机将货物从航空物流中心配送到指定地点。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.7114147909967846" data-s="300,640" data-type="png" data-w="1244" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs7TZr7UrIs4bX6vRdT5CwibVZIzwiaWD7l0ESu2HZ8Piazw37fHVZmVMQw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这一专利设想的航空物流中心（AFC）是依靠巨大的飞艇来实现的，飞艇能够飞翔在海拔 4.5 万英尺的高空，然后再利用单个的无人机来将亚马逊的货物配送给顾客。另外，小号的穿梭飞艇，它们可以给 AFC 送去货物补给、燃料和工作人员等。因为在空中进行，所以无人机的配送范围就会更广，在从空中下降配送货物的时候消耗的燃料也更少。因为空中仓库的可移动性，这让亚马逊在面临需求变更的时候可以灵活地进行库存管理。例如，假设一种情况，我们可以把 AFC 建在体育场附近，这样就在比赛进行的过程中即时提供比赛用品和零食。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;该专利的技术基于网状网络（mesh network），透过多架无人机互相沟通，分享数据，以确认位置、方向、高度及周围环境等。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.7417763157894737" data-s="300,640" data-type="jpeg" data-w="608" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsRVbKZmbEOG6Gicguibn50yKxcaGY6ExOhOnMtxyORsWFjpYGib3UyvPpQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;亚马逊也正在考虑建立多重用途的停靠站，不仅只有飞艇是无人机的基地，还可能会将建筑物、蜂窝塔（cell tower）或是路灯杆加以改造用来停靠无人机。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.9906790945406125" data-s="300,640" data-type="png" data-w="751" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs7pesp5pGZH4dncLOOl7txJwiaZHYHZTMiaVvdamyXbzFzLVicvQicfUCMQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;然后，他们揭露了无人机被攻击时的防护手段。当然，图像中的无人机是被人拿着弓箭攻击。据专利描述，如果无人机被危害到时会覆盖一层橡胶泡沫吸收动能，防止损坏。如下图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.4220532319391635" data-s="300,640" data-type="png" data-w="526" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsh8tlVAC3WYTXAWte5ibGOfjgF8c1hPN37NVKgic1L5KdxhgmVycapshg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;目前，飞行无人机仓库还停留在专利的阶段——亚马逊没有表示将会很快在我们的城市当中实现无人机配送。鉴于无人机配送项目目前在美国处于进退不前的阶段，在英国也才刚刚开始进行测试，所以要真正实现这一目标可能还需要很长的时间。但是，我们很清楚地认识到亚马逊无人机构想的前景可能是我们无法想象的，从航空物流中心（AFC）的专利就能看出这一点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="min-height: 1em; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="text-align: justify; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;</description><guid isPermaLink="false">http://chuansong.me/n/1417253642251</guid></item><item><title>专题 | 脑芯编：摆脱冯·诺依曼的深度学习硬件</title><link>http://chuansong.me/n/1417253742262</link><description>&lt;div class="rich_media_content " id="js_content"&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;从9月份&lt;/em&gt;&lt;em style="color: rgb(136, 136, 136); font-size: 12px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心机器之心联合矽说共同推出系列文章「脑芯编」开始，到现在已经发布了四篇文章，这是该系列的第五篇。对硬件感兴趣的同学依然可以后台留言，加入机器之心与矽说的硬件交流群。&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;〈五〉&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;真北路上初相见&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;不知不觉&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;《脑芯编》已经走过了上半阙&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;默默挥手告别那些弃剧的看官&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;也由衷感谢仍然愿意用手指点进来的您&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你们是撑住脑心编不烂尾的重要力量&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;与其肉麻&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;不如再念一遍诗的上半阙&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;a csmlink="BHoicc" href="http://chuansong.me/n/719987542314" target="_blank"&gt;&lt;span style="font-size: 14px;"&gt;昨夜神风送层云&lt;/span&gt;&lt;/a&gt;&lt;span style="font-size: 14px;"&gt;，（神经元与网络）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;a csmlink="CHoicc" href="http://chuansong.me/n/1009239642648" target="_blank"&gt;&lt;span style="font-size: 14px;"&gt;几重卷积几重生&lt;/span&gt;&lt;/a&gt;&lt;span style="font-size: 14px;"&gt;。（卷积神经网络）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;a csmlink="DHoicc" href="http://chuansong.me/n/1009239642648" target="_blank"&gt;&lt;span style="font-size: 14px;"&gt;梦里不知形与令&lt;/span&gt;&lt;/a&gt;&lt;span style="font-size: 14px;"&gt;，（计算体系结构）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;a csmlink="NHoicc" href="http://chuansong.me/n/1218474242942" target="_blank"&gt;&lt;span style="font-size: 14px;"&gt;烛台簇华照单影&lt;/span&gt;&lt;/a&gt;&lt;span style="font-size: 14px;"&gt;。（单指令多数据）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;上次我们讲到，现行的计算机体系结构——“冯诺依曼”结构是阻碍深度学习神经网络的一个重要瓶颈。其计算和存储分离的特点，使得神经元计算的效率低下。合理改变指令集，加入乘累加指令和SIMD（单指令多数据）指令可以缓解该问题，但仍然指标不治本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;此时，革“冯诺依曼”的命变成了很多懵逼骚年（讲的是心态，年纪可是很大哦）的选项。&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;非冯架构的深度学习硬件一时间成为了洛阳纸贵的一时之选。这个过程自然有资本主义的糖衣炮弹加持，美国国防部先进项目研究局（传说中的DARPA，可以理解为神盾局？）便在非冯架构上与世界顶级研究机构——IBM合作，搞了个叫SyNAPSE （System of Neuromophic Adaptive Plastic Scalable Electronics，其实synapse在字面上也“突触”的拼法）的项目。从第一阶段到最终，DARPA赞助了IBM 4千2百万刀，打响了深度学习抗冯的第一枪——TrueNorth（真北）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当然，很多人也把TrueNorth看作深度学习硬件发展史上打得最响的水花。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;Neuromophic，替天行道？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;任何革命都要师出有名，就算水泊梁山也有个“替天行道”的名头。那真北的“名”在哪里呢？很简单，我们要造一个真“大脑”，而不是计算机这样给冯老爷子当傀儡的“伪电脑”。英语叫做Neuromophic，神经形态的硬件。于是就有了这张图：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;img data-ratio="0.628" data-s="300,640" data-type="jpeg" data-w="750" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs7m8EHzmHH6qoU5j3umhdfpAB7aycyTbvcu7V1XsXIaTUSoHicOciauVA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;真北的设计理念，以人脑为起蓝本，依葫芦画瓢，不带点儿差的。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;IBM的工程狮从微观到宏观，将人的大脑分成三个层次——神经核团、脑功能区和脑皮层。每个核团由很多个神经元组成，每个功能区由很多核团组成，一个能完整地进行一项任务的皮层由很多个功能区组成。（是不是好久没有上过码农老师的生物课了，有没有点怀念呢？下面还有。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;对应的，真北架构下，也分为这三个层次。先做了一个核团对应的硬件——neurosynaptic core，每个core由256个输出与输入、以及对应的系数存储，并集成了神经信号的路由器（router）使得信号可以在长距离上游走；在此基础上，一块芯片有64乘64个这样的核团，共4096个，组成了一个“功能区”。而很多完整的应用和复杂的任务，还需要芯片与芯片间的互联，实现一个完整的皮层功能。看，这才是真正的神经形态的“电脑”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;TrueNorth还追求了一个大脑的特点，没有全局时钟控制的信号传递。真北只有帧时钟（1KHz，和intel的3.6GHz比慢了几百万倍哦~），并没有控制信号流的时钟，数据和数据之间采用异步的方式进行通讯，寻求高能效和低功耗。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这里留给读者一个问题：为什么是非冯呢？（提示：memory在哪里？）如果各位看官到这里眼皮还没有搭起来，可以考虑去读读TrueNorth的Science原著，保证一夜睡到天明。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;img data-ratio="1.2716763005780347" data-type="gif" data-w="346" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsOmoNfzyLrMv3dyAnL9JttcaDVTSkCJTx2WR20PFwvdl3f0R4yjMdRA/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;SpikeNN，致命缺陷？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果有一件事情，可以把昏昏欲睡的人们从周公的世界里拉回来，那一定是——撕逼。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当所有人都觉得TrueNorth要改变人类的时候，惊天一声雷从华山之巅劈下来。出手的，是在神经网络中有“东邪西毒南帝北丐”之称呼的Yann LeCun。（我们在&lt;/span&gt;&lt;a csmlink="RHoicc" href="http://chuansong.me/n/719987542314" target="_blank"&gt;&lt;span style="font-size: 14px;"&gt;脑芯编（一）&lt;/span&gt;&lt;/a&gt;&lt;span style="font-size: 14px;"&gt;中提到过他。）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;img data-ratio="0.6581532416502947" data-s="300,640" data-type="jpeg" data-w="1018" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs6LXic9BGLZDfLyictUyeSgn5r9Ej4b4g9vjiavNc1v5oI9WtqKglNxHiaA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;深度学习的“东邪西毒南帝北丐”F4&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Yann大人在Facebook上发了一篇长长的博客来表达自己对True North的不屑。这里节录部分。（冬天了，小编最近比较懒，所以靠复制黏贴凑字数）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Now, what wrong with TrueNorth? My main criticism is that TrueNorth implements networks of integrate-and-fire spiking neurons. This type of neural net that has never been shown to yield accuracy anywhere close to state of the art on any task of interest (like, say recognizing objects from the ImageNet dataset).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;简单的说，问题出在Spiking Neural Networks。Spiking的中文可以叫做脉冲，用现代的生物医学技术发现，spike是人脑中信息传递的真实电学过程。下图就是人脑中一个神经元附近测到spike信号：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;img data-ratio="0.5371287128712872" data-type="gif" data-w="404" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsUnMFhbxPzNJLkrzDEzWyHtf5rZaX6AdDzbxiaaRGcuqPwQQjZbZRRsQ/0?wx_fmt=gif"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;医学上，也叫这个信号为细胞膜动作电位（Action Potential）。事事以脑科学为准绳的TrueNorth，自然在这基础理论上一定是向生物学看齐的。可是，问题便在于，在神经网络被提出来的前几十年，就是这spike NN的英魂不散，才导致了其早期“食之无味，弃之可惜”的尴尬地位。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;就像那个最有名的比喻：因为鸟的翅膀，让人类渴望飞翔；但放弃对翅膀的模仿，才让飞机真正飞上蓝天。很多事物只能赐予灵感，却无法100%照搬，否则下场就是那些个鸟人。（这话也不是我这种小辈敢说的，同样来自Yann大人）&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;Memristor，吴下阿蒙?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一方面，如果spike完成神经信号的传递与运算真的有问题，那人类为什么聪明？ 另一方面，如果SpikeNN真的100%模仿了我们的脑子，为什么连个ImageNet分类都分不清楚？一定是哪里出了问题。答案是后者。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;首先，在我们通常使用的神经网络里面有个假设——系数（Weight）在训练完成后是固定，不改变的。这个假设在CNN/RNN等一系列架构中显得天下太平，因为系数位宽大么。但是到了SpikeNN就是个大麻烦，所有的信号是二进制的，所谓的系数只改变链接关系、延时，不改变幅度，自由度大大衰减。那我们的脑子真的是这样的么？&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;唉，生物课又来了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;虽然我们的大脑的神经元看上去是二元的，但是神经元通路还有一个可塑性维度，叫STDP （Spike Timing Dependent Plasticity），就是突触的连接强度（Plasticity，可塑性）收到输入输出脉冲（Spikie）间的时间先后（Time Dependent）关系，其本质核心如下图。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;img data-ratio="1.120331950207469" data-s="300,640" data-type="jpeg" data-w="482" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs8pCXpU2L328UNUxAglnF0LgUSW2aaKvNKf9k3umnReVlWUAqyENnag/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果输入将将早于输出，代表输入输出间是完美的因果关系，神经元联系会被增强；如果输入的脉冲稍晚于输出，那么他们之间是果因关系，神经元的联系应该要减弱。STDP被认为是我们大脑的主要学习机制，而且在不同动物上都经过了实验验证。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;问题来了，这种学习机制和CS里面主流的学习机制——Stochastic Gradient Descent (SGD，中文叫做随机梯度最速下降？) 的后馈算法有着天壤之别。小编觉得这也是目前神经网络算法与神经科学的最大分歧。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;没有STDP的真北就这样陷入了SpikeNN的坑。但话说回来，STDP这么高级的操作模型，用传统模数混合集成电路实现是非常浪费面积，且不划算的。好巧不巧，人类突然造出了一个除了电阻电容电感之外的第四类电学器件——Memristor，忆阻器。仿佛是上帝要有光，就有一缕阳光照进SpikeNN的黑暗的胡同里。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img data-ratio="0.8380681818181818" data-s="300,640" data-type="png" data-w="704" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNso2V4V0h014kMMpcQ8Jjs5ictoLFmxq9RqGKUUI7NT7Xia9djqUsibK9Mw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;对于一个电阻，两端的电压和电流成正比，对于一个电容，两段的电荷和电压正比，对于一个电感，两端的磁通量和电流正比，对于一个忆阻器，就应该是两端的磁通量和电荷成正比。虽然很抽象，但是忆阻器的实际效果就是其电阻（导通强度）受流过的电流调制。这个效果已经非常接近STDP了。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;试想，连在忆阻器两端的突触，当设定为上一层的神经元先发生spike，而下一层后发生spike，那一个正向的电路流过忆阻器，减小忆阻器阻值，加强链接。反之，负向电流流过忆阻器，增大阻值，减缓链接。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img data-ratio="0.7116154873164219" data-s="300,640" data-type="jpeg" data-w="749" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNs4V8lv0WgRiaHbLWslRlFyr5ibgSHiaPTGx69IIurgRaDILwPsgL15RcyA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;于是，大家逐渐开始相信，在真北架构上如果能用可随摩尔定律减小的微纳尺寸忆阻器，或许才是Brain Inspired Computer真正焕发春天时候。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;于是，兼容先进集成电路的高性能忆阻器就成了问题的关键。但是，作为memristor的发明者和最努力的推广者——HP，最近好像有点无奈。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;img data-ratio="0.868" data-s="300,640" data-type="png" data-w="750" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9ib7qeAzkJbnskHfbTEctNsOzVXickbY1wFSDEdNh7yF2tITeKiatfnuLp48nChJSXETKjEEhMicUHfw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但是也不要太灰心，最近intel和micron联合推得风声水起的3D Xpoint Memory被认为是某种程度的RRAM/memristor。究竟忆阻器是吴下阿蒙，还是未来的江左梅郎，还在未定之天呢。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这一期可能是脑心编目前为止最为干货满满的一期，牵涉好多paper，如果看官您的目光移驾到这里，小编我也是要这厢有礼的，不容易啊。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;”真北路上初相见“，告诉你采用非冯架构的IBM TrueNorth（真北）的出生、虐缘和不明亮也不灰暗的未来。下一次，我们要来讲讲以GPU为代表的协处理器深度学习架构——“一见泰坦误终身”。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="color: rgb(62, 62, 62); line-height: 25.6px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心发布，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;</description><guid isPermaLink="false">http://chuansong.me/n/1417253742262</guid></item><item><title>深度 | 区块链对人工智能的变革：去中心化将带来数据新范式</title><link>http://chuansong.me/n/1408170242781</link><description>&lt;div class="rich_media_content " id="js_content"&gt;
&lt;section style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; background-color: rgb(117, 117, 118); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自dataconomy&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;近年，从围棋到人类水平的语音识别，人工智能（AI）研究者终于在他们几十年一直努力探索的领域取得了突破。取得突破进展的关键一点是研究者们可以收集巨量的数据并「学习」这些数据，从而将错误率降低到可接受范围以内。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;简而言之，大数据大为改观了人工智能的发展，将其推到一个几乎难以置信的高度。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;区块链技术同样能够变革人工智能——当然以它自己的特定方式进行。部分将区块链用于人工智能方式目前还很单一，比如在人工智能模型上进行审计跟踪（audit trail）。有些应用几乎是难以置信的，比如拥有自己的人工智能——人工智能去中心化自治组织（AI DAO）。这些都是发展的机会。这篇文章将具体探讨这些应用。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;作为蓝海数据库的区块链（blockchain）&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在讨论这些应用之前，我们先来了解一下区块链与传统大数据的分布式数据库（比如 MongoDB）之间的差异。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们可以将区块链视为「蓝海」数据库：它们逃离了现有市场上有鲨鱼竞争的「红海」，而是没有市场竞争的蓝海。蓝海的著名例子是视频游戏主机 Wii（妥协了原始性能，但添加了新的互动模式），或 Yellow Tail 葡萄酒（忽略了葡萄酒爱好者矫揉造作的繁复规范，使葡萄酒更容易被啤酒爱好者接受）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;根据传统的数据库标准，传统的区块链（如比特币）是糟糕的：低吞吐量、低容量、高延迟、糟糕的查询支持等。但在蓝海思维中，这是可以接受的，因为区块链引入了三个新特性：去中心化/共享控制、不变性/审计跟踪和本地资产/交换。受比特币启发的人们乐于忽视传统的以数据库为主的缺点，因为这些新的好处有可能以全新的方式影响整个行业和社会。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这三个新的「区块链」数据库特征对于人工智能应用也有潜在的借鉴意义。但是大多数实际的人工智能工作涉及大量的数据，如大数据集训练或高吞吐量流处理（stream processing）。因此，对于区块链在人工智能领域的应用，需要具有大数据可扩展性和查询的区块链技术。像 BigchainDB 这样的新兴技术及其公共网络 IPDB（Internet Pinball Machine Database）正是如此。这使得获得区块链的好处时不再需要舍弃传统的大数据数据库的优点。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;人工智能区块链的概述&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;大规模的区块链技术解锁了其在人工智能应用上的潜力。从区块链的三点好处开始，我们来探讨一下这些潜力。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio="0.5625" data-s="300,640" data-type="png" data-w="800" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLYYadz8K9SpkKzO0NP07NsYNDebctZrXxsVNXChcV8dh7JJv3IqGAlA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这些区块链的好处为人工智能实践者带来了以下机会：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;去中心化/共享控制激励了数据共享：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;（1）带来更多的数据，因此可以训练出更好的模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;（2）带来新的定性数据，因此新的定性模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;（3）允许共享控制人工智能的训练数据和模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;不变性/审计跟踪：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;（4）为训练/测试数据和模型提供了保证，提高数据和模型的可信度。数据也需要声誉。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;本地资产/交换：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;（5）使训练/测试数据和模型成为知识产权（Intellectual Property/IP）资产，这可以带来去中心化的数据和模型交换。能更好地控制数据的上游使用。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;还有一个机会：（6）人工智能与区块链解锁人工智能去中心化自治组织（AI DAO/Decentralized Autonomous Organizations）的可能性。这些人工智能可以积累财富。在很大程度上，它们就是软件即服务（Software-as-a-Service）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;区块链还可以以更多的方式帮助人工智能。反过来，人工智能可以有许多方法帮助区块链，如挖掘区块链数据（例如 Silk Road 调查）。这是另外的讨论话题: )&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;许多这些机会是关于人工智能与数据的特殊关系。让我们先来探讨一下。在此之后，我们将更详细地探讨区块链在人工智能领域的应用。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;人工智能 &amp;amp; 数据&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在这里，我将描述现代人工智能为了产生好的结果是怎样利用大量数据的。（虽然不总是这样，但它很常见并值得描述。）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;「传统」人工智能 &amp;amp; 数据的历史&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当我在 90 年代开始做人工智能研究时，一个典型的方法是：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;找到一个固定的数据集（通常很小）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;设计一种算法来提高性能，例如为支持向量机分类器设计一个新的核函数，以提高 AUC 值。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在会议或期刊上发表该算法。「最小可发表的改进程度」只需要相对提高 10％，只要你的算法本身足够花哨。如果你的提高程度在 2 倍-10 倍 之间，你可以发表到该领域最好的期刊了，特别是如果算法真的很花哨（复杂）的话。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果这听起来很学术，那是因为它本身就很学术。大多数人工智能工作仍然在学术界，虽然有实际的应用场景。在我的经验中，许多人工智能子领域中都是这样的，包括神经网络、模糊系统（fuzzy system）、进化计算（evolutionary computation），甚至不那么人工智能的技术，如非线性规划或凸优化。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在我第一篇发表的论文《Genetic Programming with Least Squares for Fast, Precise Modeling of Polynomial Time Series》（1997）中，我自豪地展示了我新发明的算法与最先进的神经网络、遗传编程等相比在最小的固定数据集上有最好的结果。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;走向现代人工智能 &amp;amp; 数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但是，世界变化了。2001 年，微软研究人员 Banko 和 Brill 发表了一篇有着显著成果的论文。首先，他们描述了大多数自然语言处理领域的工作基于小于 100 万字的小数据集上的情况。在这种情况下，对于旧/无聊/不那么花哨的算法，错误率为 25％，如朴素贝叶斯（Naive Bayes）和感知器（Perceptron），而花哨的较新的基于记忆的算法（memory-based algorithms）实现了 19％的错误率。这是下面最左边的四个数据点。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.6991643454038997" data-s="300,640" data-type="png" data-w="718" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLw8ZdZorSPcTkcq06C4yjlt8eOxQHTIZutMdsd7G2ibOW8mgKfibvIfsw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;到目前为止，还没有什么让人惊讶的。但是，Banko 和 Brill 揭示了一些不同寻常的东西：当你添加更多的数据——不仅仅是一点数据，而是多达数倍的数据——并保持算法相同，那么错误率会持续下降很多。到数据集大到三个数量级时，误差小于 5％。在许多领域，这是 18％到 5％之间的差异，但是只有后者对于实际应用是足够好的。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;此外，最好的算法是最简单的；最糟糕的算法是最花哨的。来自 20 世纪 50 年代的无聊的感知器算法正在击败最先进的技术。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;现代人工智能 &amp;amp; 数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Banko 和 Brill 并不是唯一发现这个规律的人。例如，在 2007 年，谷歌研究人员 Halevy、Norvig 和 Pereira 发表了一篇文章，显示数据可以如何「不合理地有效」跨越许多人工智能领域。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.47435897435897434" data-s="300,640" data-type="png" data-w="312" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLBxSrbHIAFcBDQL7BlxicJP2DxzpQWKUA09ibMBpEhK7OJsNJFMKZsaibQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这就像原子弹一样冲击了人工智能领域。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;数据才是关键！&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;于是收集更多的数据的竞赛开始了。需要大量的努力才能获得好数据。如果你有资源，就可以得到数据。有时甚至可以锁定数据。在这个新世界里，数据是壕沟，人工智能算法是一种商品。出于这些原因，「更多数据」是谷歌、Facebook 等公司的关键。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;「越多数据，越多财富」——每个人&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一旦你了解这些动态，具体行动就有了简单的解释。谷歌收购卫星成像公司不是因为它喜欢卫星图像；而谷歌又开放了 TensorFlow。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习直接适用于这种情境：如果给定一个足够大的数据集，它能弄清楚如何获取相互影响和潜在变量。有趣的是，如果给予相同的大规模数据集，来自上世纪 80 年代的反向传播神经网络有时能与最新的技术媲美。参考论文《Deep Big Simple Neural Nets Excel on Handwritten Digit Recognition》。所以说数据才是关键。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作为一个人工智能研究员我自己成熟的年龄是类似的。当我遇到现实世界的问题时，我学会了如何吞下我的骄傲，放弃「炫酷」的算法，仅仅满足能够解决手头上问题，并学会了热爱数据和规模。我们将重心从自动化的创意设计转向了「无聊」的参数优化；同时当用户要求我们从 10 个变量增加到 1000 和变量时，我们在匆忙应对中变得不那么无聊——我的第一家公司 ADA（1998–2004）的情况就是这样。我们将重心从华丽的建模方法转移到超级简单但可完全扩展的机器学习算法（如 FFX）；当用户要求从 100 个变量增加到 100000 个，从 100 亿蒙特卡洛样本增加到 10 亿（有效样本），我们同样不无聊——这发生在我的第二家公司 Solido（2004—至今）。即使是我第三家也是目前的公司的产品 BigchainDB，也体现了对规模的需要（2013—至今）。扩展功能，扩大规模。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;机会 1：数据共享→更好的模型&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;总之：去中心化/共享控制能促进数据共享，这反过来又带来更好的模型、更高的利润/更低的成本/等。阐述如下：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt; &lt;img data-ratio="0.5625" data-s="300,640" data-type="png" data-w="800" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLIQttOmYuuh6ed8nVsfibDCGbCBSgDgtP2OU59uXQu2uic2BicWFayzQhA/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;人工智能热衷数据。数据越多，模型越好。然而，数据往往是孤立的，尤其是在这个新世界里，数据可能是难以逾越的鸿沟。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但是如果有足够的正面效益，区块链鼓励传统的独立体间数据共享。区块链的去中心化本质鼓励数据共享：如果没有单一的实体控制存储数据的基础设施，共享就会有更少的冲突。之后我会举出更多好处。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;数据共享可能发生在一个企业中（如在区域办公室）、一个生态系统内（如一个「财团」数据库）或整个星球（例如共享行星数据库，即公开区块链）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;下面给出了每个对应的例子：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;企业内&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;：使用区块链技术来合并来自不同区域办公室的数据，因为它能降低企业审核自己数据的成本，并和审计员共享数据。随着新的数据到位，企业可以建立人工智能模型，例如，相比以前只建立在区域办公室水平的模型，新模型能更好地预测客户流失的模型。每个区域办公室的「数据集市」？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;生态系统内&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;：竞争对手（例如，银行或唱片公司）过去永远不会分享他们的数据。但现在可能坦率地展示，结合几个银行的数据，可以做更好的模型以预防信用卡欺诈。或者供应链机构通过区块链共享数据，对供应链中更早地数据使用人工智能，可以更好地确定在供应链中导致失败的根本原因。例如，大肠杆菌的菌株究竟出现在哪里？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;在整个星球范围内（公共区块链数据库）&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;：考虑不同生态系统之间的数据共享（例如能源使用数据+汽车零部件供应链数据）；或个人参与者在一个行星尺度的生态系统（如网络）。更多的数据来源可以改善模型。例如，在中国一些工厂能源使用量的峰值可能与非法汽车零部件花了一天在市场运输有关。总的来说，我们看到公司汇总数据，进行洗白，重新包装并出售的行径；从 Bloomberg 终端到几十（或几百个）初创企业通过 http APIs 销售数据。我在稍后阐述这一未来。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;敌人们共享他们的数据来喂养一个人工智能。2016 多么有趣！&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;机会 2：数据共享→新模型&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在某些情况下，当独立的数据被合并，你不只是得到一个更好的数据集，还得到一个新的数据集。这能带来全新的模型，从中你可以收集新的见解、进行新的业务应用。也就是说，你可以做一些你以前不能做的事情。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这里有一个用于识别钻石欺诈例子。如果你是一家提供钻石保险的银行，你想开发一个识别钻石是否欺诈的分类器。在地球上有四个值得信赖的钻石认证实验室（当然取决于你问谁）。如果你只能访问其中一个实验室的钻石数据，那么你就看不到其他三家的数据，你的分类器可能很容易把其他家的钻石标记为欺诈（见下图，左）。你的误报率会使你的系统不可用。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;相反如果区块链促进四个认证实验室共享他们的数据，你就有所有的合法数据，从利用它们你将建立一个分类器（右下）。任何输入的钻石，例如在 eBay 上看到，将遍历系统，并与分类器中的每一类进行比较。该分类器可以检测真实的欺诈行为，避免误报，从而降低误报率，使保险供应商和认证实验室受益。这可以简单地作为一个查找框，即不需要人工智能。但使用人工智能进一步提高了它，例如基于颜色、克拉预测价格，然后用「价格和价值的接近程度」作为主要欺诈分类器的输入。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio="0.5625" data-s="300,640" data-type="png" data-w="800" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLGBrBvqahLQNkkvXibtDlYy00SIx2lqtS6qSwUdaltMnJaibFicpazXxYg/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这里的第二个例子是，去中心化系统中的一个适当的 token 激励机制（token-incentive scheme）可以激励先前未标记的数据集得到标记，或者是以一个更经济的方式进行标记。这基本上就是去中心化的 Mechanical Turk（亚马逊的众包服务平台）。有了新标签，我们就得到了新数据集；我们使用新数据集进行训练以获得新模型。第三个例子是，token 激励机制可能会导致来自物联网设备的直接数据输入。这些设备控制数据并可以将其交换为资产，比如能源。同样地，这个新数据可能会带来新模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;囤积 vs 分享？&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;此处的两个相反动机之间有一个紧张关系。一个是囤积数据——即「数据是新护城河」的观点；另一个是共享数据，为了得到更好的/新的模式。分享行为必须要有一个超过「护城河」效益的足够驱动力。技术驱动力是得到更好的模式或新的模式，但这个驱动力必须要有商业价值。可能带来的利益包括降低原材料或供应链中的保险储蓄诈骗；将 Mechanical Turk 作为赚钱副业；数据/模型交换；或是对抗强大的核心玩家的集体行动，就像唱片公司合力对抗苹果的 iTunes 一样，等等；它需要创造性的商业策略。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;中心化 vs 去中心化？&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;即使一些组织选择分享数据，他们也可以在无需区块链技术的情况下这样做。例如，他们可以简单地将其囤入 S3 实例中并提供出 API。但在某些情况下，去中心化带来了新的好处。首先是基础设施的直接共享，这样共享联盟中的任一组织就不会自己控制所有的「共享数据」。（这在几年前是一个主要的障碍，那时唱片公司尝试过为一个公共注册系统而合作。）另一个好处是让数据 &amp;amp; 模型转变为资产变得更加容易，然后这样可以进行外部授权以获利。我下文会详细阐述这一点。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如前所述，数据 &amp;amp; 模型共享会发生在三个层次：在一家企业内部（跨国公司的情况比你想象的要难）；在一个生态系统或联合体中；或在这个星球中（相当于成为一个公用事业）。让我们更深入地探索这个行星尺度的分享吧。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机会 2A：行星层次的新数据 → 行星层次的新见解&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;整个星球层面的数据共享可能是最有趣的。让我们进一步深入这个问题。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;IPDB 是全球范围的结构化数据，而不是零碎的。将万维网视为互联网上的文件系统；IPDB 是其数据库副本。（我认为我们没有看到更多相关工作的原因，在于语义上的 Web 工作试图以升级文件系统的角度去实现它。但通过「升级」文件系统来建立数据库是相当困难的！如果从一开始就说你正在建立一个数据库并设计它之类的话，这样更有效果。）「全局变量（Global variable）」会得到更加字面上的解释 : )（注：global 也有「全球」的意思）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;那么，当我们有一个行星尺度的、像 IPDB 那样的数据库共享服务，或是怎样一番景象？我们有几个参考点。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;第一个参考点是，在企业界的公共数据管理与重新包装使其更易被消费方面&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;，从简单的天气或网络时间的 API，到股票和货币之类的金融数据 API，最近已经有一个十亿美元的市场了。想象一下，所有这些数据都可通过一个单一的数据库以一种类似的结构化方式（即使只是一个 API 的通行证）进行访问。就好像有了 1000 个彭博社。不用担心受制于某个单一的实体。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;第二个参考点来自于区块链，即通过一个区块链来「oraclize」外部数据使其易于消费的概念。&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;但我们可以 oraclize 一切。去中心化的彭博社只是开始。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;总体而言，我们得到了数据集与数据源多样性的一个全新规模。因此从性质上讲，我们有了新数据。行星层次的结构化数据。由此从性质上讲，我们可以建立新的模型，使得之前没有联系的输入 &amp;amp; 输出之间产生关联。有了模型，我们将获得性质上的新见解。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我希望此处可以说得更具体一些，但是它太新了，我想不出任何例子。不过，它们会出现的！&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;还会有一个 Bot 角度的。我们一直假定区块链 API 的主要消费者会是人类。但如果是机器呢？现代 DNS 的创造者 David Holtzman 最近说，「IPDB 是人工智能的饲料（kibbles）」。分析一下，这是由于 IPDB 实现并鼓励了行星层次的数据共享，而人工智能实在是很喜欢吃数据。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.5625" data-s="300,640" data-type="png" data-w="800" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLmv1K3XJIupf4xm2lRymcZo4JvxXicl2O1lsywtwJ2VNuP19jTWF21ug/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;机会 3：数据 &amp;amp; 模型中的审计跟踪使预测结果更加值得信赖&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;此应用针对的是这样一个事实：如果你使用垃圾数据进行训练，那么你将得到一个垃圾模型。数据测试同理：垃圾进，垃圾出。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;垃圾可能来自于恶意行事者/可能篡改了数据的拜占庭式故障。想一下大众汽车的排放丑闻。垃圾也可能来自于无恶意的演员/崩溃式故障，例如有缺陷的物联网传感器、一个出错的输入数据，或是环境辐射引起的一点波动（没有良好的纠错行为）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你怎么知道 X / y 训练数据没有缺陷？现场使用呢，在现场输入的数据上运行模型的情况？那么模型预测（yhat）呢？简而言之：进入模型以及来自模型的数据都经历了什么？数据也要名誉。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.5625" data-s="300,640" data-type="png" data-w="800" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLicYlCnXKJOBPOgiaglzZibxTs1CWibZdOToiaWFjgRtCJ0Gtd96Rdk3RQFQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;区块链技术可以给以帮助。下面讲具体做法。在过程的每一步中都建立模型，并在该领域运行模型，该数据的创造者可以简单地为模型加上区块链数据库的时间戳，包括数字签字以声明「我相信这一点上的此数据/模型是没问题的」。再具体一点就是…&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;建模来源：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;传感器数据（包括物联网）。你相信你的物联网传感器对你说的话吗？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;训练输入/输出（X / y）数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;建模本身，比如你可以使用可信执行（Trusted execution）基础设施，或是进行复核计算的 TrueBit 式的市场。至少有建模型收敛曲线的建模证据（例如 nmse* *vs. epoch）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;模型本身。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;测试过程/该领域中的来源：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;测试输入（X）数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;模型仿真。可信执行、TrueBit 等。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;测试输出（yhat）数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们可以在模型的建立与应用过程中得到其来源。其结果是更可信的人工智能训练数据 &amp;amp; 模型。我们还可以拥有这样的连锁结构。模型的模型，就像在半导体电路设计中那样一直到底。现在，一切都有出处了。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;好处包括：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;（在最广泛的意义上）捕捉所有层次上的数据供应链中的漏洞。例如你可以判断传感器是否在说谎。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你知道数据和模型的来历，并且是以密码验证的方式。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;您可以在数据供应链中发现漏洞。这样一来，如果发生错误，我们能更好地了解其位置以及如何应对。你可以将其当做银行式的和解，不过针对的是人工智能模型。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;数据有了名誉，因为多双眼睛都可以检查那个源，并甚至声称自己的数据判断如何有效。相应地，模型也有了声誉。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;机会 4：训练数据 &amp;amp; 模型全球共享注册系统&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但是如果我们有一个可以方便管理另一个数据集或数据馈送（免费或其他）的全球数据库呢？这包括一系列出自各种机器学习比赛的 Kaggle 数据集、斯坦福 ImageNet 数据集及其他不计其数的数据集。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.5625" data-s="300,640" data-type="png" data-w="800" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLhSafE6nfU4r8b3bhQBpGzhXPAufnRwUpTpxrK6iae9DK0F0ic9YBwPvw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这正是 IPDB 可以做到的。人们可以提交数据集并使用其他人的数据。数据本身会在一个去中心化的文件系统中，就像 IPFS ；而元数据（及数据指针本身）将会在 IPDB 中。我们会获得一个人工智能数据集的全局共享空间。这有助于实现打造数据开放社区的梦想。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们无需停留在数据集层面；我们也可以包括从这些数据集中建立起来的模型。抓取和运行他人的模型并提交自己的模型应该很容易。一个全球性的数据库可以大大方便这一过程。我们可以得到行星所拥有的模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;机会 5：作为 IP 资产的数据 &amp;amp; 模型→数据 &amp;amp; 模型交换&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;让我们基于训练数据和模型的「全局共享注册系统」这一应用。数据 &amp;amp; 模型可以成为公共共享内容的一部分。但它们也可以进行购买与出售！&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;数据和人工智能模型可以被用来作为知识产权（IP）资产，因为它们受到版权法的保护。这意味着：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果你创建了数据或模型就可以要版权。无论你是否想进行任何商业行为。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果你拥有数据或模型的版权，那么你可以将使用权限授权给其他人。例如，你可以将你的数据授权给其他人来构建他们自己的模型。或者你可以将你的模型授权给其他人并计入他们的移动应用程序。次级授权、次次级授权等也是可能的。当然你也可以从他人那里获得数据或模型授权。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我认为能够拥有一个人工智能模型的版权并进行授权，这是相当棒的。数据已被公认为是一个潜在的巨大市场；模型会紧跟其上。在区块链技术之前是可以对数据 &amp;amp; 模型宣称版权与许可的。相关法律的出台已经有一段时间了。但区块链技术使它变得更好，因为：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;版权声明提供了一张防篡改的全球公共注册表；你的版权声明是数字化/加密了的签名。此注册表也可以包括数据 &amp;amp; 模型。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;对于你的授权交易，它也提供了一张防篡改的全球公共注册表。这次不仅仅是数字签名；&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;相反除非你有私钥，否则你甚至不能转让权利。权利转移是作为一个区块链式的资产转换进行的。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在我 2013 年致力于使用 ascribe 来帮助数字艺术家们获得报酬的过程中，区块链上的 IP 与我心心相映。最初的方法有规模和许可灵活度的上的问题。现在这些都已经被克服，我最近写的相关文章有谈到这点（https://medium.com/ipdb-blog/a-decentralized-content-registry-for-the-decentralized-web-99cf1335291f#.v3jl6f9om）。这项技术包括：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Coala IP 是一个灵活的、区块链友好的 IP 协议。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;IPDB（及 BigchainDB）是一个公共的区块链共享数据库，用来存储权利信息及其他网络规模的元数据。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;IPFS +物理存储（比如 Storj 或 Filecoin）是一个去中心化的文件系统，用来存储大数据 &amp;amp; 模型斑点。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;有了这个，我们就有了数据与模型作为 IP 资产。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;例如使用 ascribe 时，我声明了于几年前建立的一个人工智能模型的版权。该人工智能模型是一个决定使用哪种模拟电路拓扑的 CART（决策树）。这是它的密码防伪证书（Certificate of Authenticity /COA）。如果你想从我这获得一个许可版本，给我发电子邮件即可: )&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.5625" data-s="300,640" data-type="png" data-w="800" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLxIWT6mlyK3Z1Yv8rceOxYmbg8K2qrcvg241ttWgYiaiaCicbIP3SgkiaVw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一旦我们有了数据和模型作为资产，我们就可以开始进行资产交换。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一次交换可以是中心化的，像 DatastreamX 处理数据那样。但到目前为止，它们确实只能使用公共数据源，因为很多企业觉得分享的风险比效益要多。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;那么去中心化的数据 &amp;amp; 模型交换呢？对「交换」过程中所共享的数据进行去中心化，这样做有新的好处。去中心化过程没有一个单一的实体去控制数据存储基础设施，也没有谁拥有什么的分类账本，如前所述，这更易于组织合作或数据共享。比如用于 Deep Nets 的 OpenBazaar。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;有了这样一个去中心化的交换，我们会看到一个真正的开放数据市场的出现。这实现了数据与人工智能团体间的（包括你的）长期以来的一个梦想。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.5625" data-s="300,640" data-type="png" data-w="800" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlL1fkIlS2JGPTSbJN5iaPCuuJX1IecvstiaT4TLGkLiapJm7q1y4uOTgmzQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当然在这些交换之上也会产生一些基于人工智能算法的交易：用人工智能算法购买人工智能模型。人工智能交易算法甚至会变成这个样子：购买算法来交易人工智能模型，然后自己进行更新！&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机会 5A：在上游控制你的数据 &amp;amp; 模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这是之前应用的重复。在你登录 Facebook 时就授予了它非常具体的权利，包括对你输入进其系统中的任何数据的处置权限。它会对你的个人资料施加许可。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当一个音乐家用一个标签来签名时，他们就是在授予标签非常具体的权利：编辑音乐、分发音乐等等。（通常该标签会试图攫取所有版权，这个任务非常繁重，但那是另一回事了！）&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;人工智能数据和人工智能模型也同理。当你创建可用于建模的数据以及创建模型本身时，你可以预先指定许可从而在上游限制其他人的使用权限。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;对于所有用例，从个人资料到音乐、从人工智能数据到人工智能模型，区块链技术使这个过程变得更加容易。在区块链数据库中，你是将权限作为资产，例如一个读取权限或查看某条数据/模型的权利。你作为权利持有人可以将这些作为资产的权限转让给系统中的其他人，类似于比特币的转让：创建转让交易并用你的私人密钥签名。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;有了这个，你就有可以更好地从上游控制你的人工智能训练数据、你的人工智能模型等等。「例如，你可以将这些数据进行混合却不能进行深入学习。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这和 DeepMind 在其医疗保健区块链项目（healthcare blockchain project）中所采用的部分战略有点像。在数据挖掘中，医疗数据会带来监管和反垄断问题的风险（尤其是在欧洲）。但如果用户可以真正拥有自己的医疗数据并控制其上游使用，那么 DeepMind 就可以仅仅告诉消费者和监管机构说「嘿，实际上客户拥有自己的数据，我们只是拿来用而已」。我的朋友 Lawrence Lundy 提供了这个好例子，然后他进一步推断：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;完全可能的是，政府会允许数据私有（人类或 AGI）的唯一方式是一个数据共享基础设施，「网络中立」规则，就像 AT&amp;amp;T; 公司和原始的那种电话线。在这个意义上，越来越多的自主人工智能会要求政府接受区块链及其他数据共享基础设施，从而实现长远的可持续性。- Lawrence Lundy&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;机会 6：人工智能去中心化自治组织（Decentralized Autonomous Organization/DAO）——可以积累财富且无法关闭的人工智能&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这是一个谎言。一个 AI DAO 属于人工智能自身，你无法关闭它。&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;我下文会总结「如何做」。感兴趣的读者可以继续阅读深入该话题。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;到目前为止，我们谈论了区块链作为去中心化数据库的内容。但我们也可以去中心化处理过程：基本上就是一个状态机的存储状态。周围有一些基础设施的话做起来更容易，而那就是「智能合同（smart contracts）」技术（比如 Ethereum）的本质。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.4575" data-s="300,640" data-type="png" data-w="800" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLRRbU9XS2AjV9ia4tibjPSfHU0cEk6Y4cziauIyAZg0VicDuh7XWn9z5q3A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们之前已经以计算机病毒的形式进行了过程去中心化。没有单个实体拥有或控制它们，而且你不能将其关闭。但它们有限制——它们主要是会试图攻破你的计算机，就是这些。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但是，如果你可以与过程进行更丰富的互动，且过程本身可以积累财富呢？目前，通过在过程中使用更好的 API（如智能合同语言）和去中心化价值储存（如公共区块链）就可以实现它。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一个 DAO 是一个体现这些特征的过程。其代码可以拥有自己的东西。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio="0.53375" data-s="300,640" data-type="png" data-w="800" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLW1xBlSrErcPHSqvxias8XRRlhZGXkjprQ36qGQ2P7tcU9XJ5ZsKzBzQ/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;是什么把我们带向了人工智能。最有可能的是被称为「人工通用智能」（Artificial General Intelligence/AGI）的人工智能子领域。AGI 和环境中的交互的自主代理有关。AGI 可以被模型化为一个反馈控制系统。这是个好消息，因为控制系统有很多优点。首先它们有深厚的数学基础，这可以追溯到 20 世纪 50 年代（Wiener 的「控制论（Cybernetics）」）。&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;它们捕捉与世界之间的互动（驱动和传感），并（基于内部模型和外部传感器来更新状态）适应它。控制系统得到了广泛的应用。它们决定了一个简单的恒温器如何去适应目标温度。它们消除了高价耳机中的噪音。它们处于成千上万的设备的中心，从烤箱到车里的刹车装置。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;人工智能社区最近对控制系统的接受程度更加热烈了。比如，它们是 AlphaGo 的关键所在。而且 AGI 本身就是控制系统。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一个 AI DAO 就是一个运行在去中心化处理 &amp;amp; 存储载体之上的 AGI 式控制系统。其反馈回路会自行进行继续，输入、更新状态、执行输出，循环往复地使用这些资源。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="1.1376146788990826" data-s="300,640" data-type="png" data-w="545" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLTuvib7wXRfbHXjL4qaMHaNY2NHVElHG1AsaFpkDVs1AsEqnlqSAtq1A/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们可以从一个人工智能入手来得到一个 AI DAO（一个 AGI 代理），并使其去中心化。或者我们可以从一个 DAO 入手并赋予其人工智能的决策能力。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;人工智能获取其丢失的链接：资源。DAO 得到其丢失的链接：自主决策。正因为如此，AI DAO 的使用范围比 AI 或 DAO 本身更大。其潜在影响也是成倍的。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这里有一些应用：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一个 ArtDAO，创建自己的数字艺术并进行销售。概括地说，它可以做 3D 设计、音乐、视频甚至是整部电影。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;有自我身份的自动驾驶汽车。概括地说就是之前的任何人工智能应用现在是「属于自己」的了。未来的情况或许是人类一无所有而只是向 AI DAO 租用服务。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;任何注入人工智能的 DAO 应用程序。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;有更多自主性的任何去中心化 SaaS 应用程序。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;详情见 AI DAOs Part II . 有一些非常可怕的… https://medium.com/@trentmc0/wild-wooly-ai-daos-d1719e040956#.r6akj4ne0&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;本文基于我个人在人工智能和区块链研究方面的经验，描述了区块链技术可以如何辅助人工智能。二者结合一处即发！区块链技术——尤其是行星尺度的——可以帮助实现人工智能和数据团体长期以来的一些梦想，并打开一些机会。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;总结如下：&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.5625" data-s="300,640" data-type="png" data-w="800" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLjqG3VAf23VnVBXTybMgVME3rSxvDmjW8HqiaoicOn9qibfV8gDBMLYiavw/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="min-height: 1em; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="text-align: justify; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;</description><guid isPermaLink="false">http://chuansong.me/n/1408170242781</guid></item><item><title>基础 | 初学者必读：从迭代的五个层面理解机器学习</title><link>http://chuansong.me/n/1408170342769</link><description>&lt;div class="rich_media_content " id="js_content"&gt;
&lt;section style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; background-color: rgb(117, 117, 118); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自Elite Data Science&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：Jane W、吴攀&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; text-align: justify; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/p&gt;&lt;blockquote style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你能猜到这个谜语的答案吗？&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果你学习机器学习，它将随处可见……&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果你是一个程序员，你会用它上千次……&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果你练习过任何技术，这俨然是第二个你……&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;不，答案不是狂饮咖啡……而是「迭代（iteration）」！&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;是的，迭代是为了实现某种结果而重复一组任务的过程。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;等等，这难道不是词典的定义吗？好吧，是的，这就是迭代真正的意思。我们并不是要揭开一些令人兴奋的秘密。但我们希望以一种对你来说可能是新的方式来构建这个简单的概念。我们的目标是从不同的角度概览机器学习的基本概念，这有别于教科书里的常规方法。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们知道，大多数书都按照正向顺序（sequential）讲解机器学习的过程：加载数据、预处理、拟合模型、预测等。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这种顺序方法当然是合理和有帮助的，但现实的机器学习很少如此线性。相反，实用机器学习有一个特殊的循环（cyclical）性质，需要不断的迭代、调整和改进。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;因此，我们想展示简单的迭代技术是如何在机器学习中具有美丽形式和深刻意义的。这篇文章是针对初学者写的，但更有经验的读者也不妨一读。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="font-size: 12px; line-height: normal; font-family: Helvetica;"&gt;&lt;img data-ratio="0.525" data-s="300,640" data-type="jpeg" data-w="640" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLISYUTpPJPqXNQybJeheRxAvAHW7ribFJkWOkTYgyNEKb3xX3V8tK5qw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;为什么讨论迭代问题？&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;迭代是机器学习的核心概念，它在许多方面至关重要。了解这个简单的概念在机器学习工作流程中的确切位置，这会带来很多切实的好处：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;1. 你能更好地理解算法&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2. 你能制定出更实际的项目进度时间表&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;3. 你会发现更容易实现的模型改进方法&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;4. 帮助你更容易坚持下去，即使初步结果较差&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;5. 帮助你进一步解决机器学习中更复杂的问题&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;根据经验，以迭代的角度看机器学习的工作流，能够帮助初学者了解机器学习背后的概念。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;所以不用多说，让我们开始介绍机器学习迭代的 5 个层面吧。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;目录&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;模型层面：拟合参数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;微观层面：调试超参数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;宏观层面：解决问题&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;元数据层面：改进数据&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;人类层面：提升自己&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;模型层面：拟合参数&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;迭代能够起到重要作用的第一个层面是模型层面。任何模型，无论是回归模型、决策树还是神经网络，都是由许多（有时甚至数百万）模型参数定义的。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;例如，回归模型由回归系数定义，决策树由节点分类的方式定义，神经网络由连接各层的权重定义。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;然而机器是如何学习正确的模型参数值的？其中迭代算法发挥了作用！&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;用梯度下降法拟合参数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;梯度下降算法（或随机梯度下降/stochastic gradient descent）是机器学习的巨大成功。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;梯度下降是一种迭代方法，用于找到函数的最小值。在机器学习中，该函数通常是损失（loss）（或成本/cost）函数。「损失」指的是衡量预测错误代价的量化指标。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;给定一组参数，梯度下降计算对应模型的预测损失，然后调整这些参数以减少损失。重复这一过程，直到损失不能进一步减少。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;最小化损失的最后一组参数就是最终的拟合模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;直观的梯度下降算法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们不会在这里推导梯度下降的数学公式，但我们将直观的给出梯度下降的概念：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;1. 设想带有山谷和山峰的山脉（损失函数）；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2. 山脉的每个位置（参数集）都有一个高度（损失）；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;3. 现在把一个滚珠放在山脉的某个地方（初始化）；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;4. 在任何时刻，球沿最陡的方向（梯度）滚动；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;5. 它继续滚动（迭代），直到它卡在某个山谷底部（局部最小）；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;6. 理想情况下，你想找到最低的山谷（全局最小）；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;7. 有很多聪明的方法来防止球被卡在局部最小值（例如初始化多个球，给它们更多的动量，以便球可以越过小山丘等）；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;8. 对了，如果山地形状像碗（凸函数），那么球一定能到达最低点。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在下面的视频中，吴恩达进一步讲述了梯度下降算法背后的原理。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="http://v.qq.com/iframe/preview.html?vid=n0360g3b2ju&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;想要学习更多梯度下降算法的数学推导，我们推荐下面的资料：&lt;/span&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;UCLA 的数学优化课程讲义：http://www.math.ucla.edu/~wotaoyin/math164/slides/wotao_yin_optimization_lec07_gradient_methods.pdf&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;scipy-lectures.org 网站的数学优化学习笔记：http://www.scipy-lectures.org/advanced/mathematical_optimization/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在实践中，调用机器学习的应用包（如 Scikit-Learn）时，并不需要从头开始编写梯度下降算法。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;微观层面：调试超参数&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;下一个迭代发挥巨大作用的层面是我们所谓的「微观」水平，更通常被称为通用模型或模型族（model family）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你可以将模型族视为广泛类别的具有可定制结构的模型。logistic 回归、决策树、支持向量机（SVM）和神经网络实际上都是不同的模型族。在实际拟合模型参数之前，每个模型族都有一组结构可供选择。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;例如，在 logistic 回归族中，可以使用 L1 或 L2 正则化惩罚项（regularization penalty）来构建单独的模型。在决策树族中，可以选用不同结构的模型，例如树的深度（depth）、修剪阈值（pruning threshold）或分割标准（splitting criteria）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这些结构选择变量称为超参数（hyperparameter）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;为什么超参数很特别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;超参数是无法使用梯度下降或其它优化算法直接从数据学习的「更高级」参数。它们描述了在拟合模型参数之前必须确定的关于模型的结构信息。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;所以当人们说他们要「训练一个 logistic 回归模型」时，他们真正的意思包含了两个阶段的过程。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;首先，决定模型族的超参数。例如，模型是否应该添加 L1 或 L2 惩罚项以防止过拟合（overfitting）？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;然后，根据数据拟合模型参数。例如，如何拟合模型系数（coefficient）以最小化损失函数（loss function）？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们之前讨论了梯度下降如何帮助执行步骤 2。但是为了使用梯度下降拟合模型参数，必须首先从模型族入手设置超参数。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;那么我们如何处理步骤 1，找到模型族的最佳超参数？&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;使用交叉验证调试超参数&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;交叉验证（cross-validation）是在众多场景最有用的技术之一，在使用它时几乎有一种作弊的感觉。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在此背景下，交叉验证也是一种迭代方法，用于评估用给定的一组超参数构建的模型的性能。这是一种重复使用训练数据的聪明方式，将它分割成几块并循环使用它们（详情见下一小节）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;使用交叉验证，你可以仅使用训练集来拟合和评估具有各种超参数集的模型。这意味着你可以将测试集单独拿出来（hold-out set）并用于最终模型选择（更多内容将在下一部分中介绍）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="417" src="http://v.qq.com/iframe/preview.html?vid=j0360bvciql&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="556"&gt;&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;交叉验证详细步骤&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;以下是使用 10 折交叉验证选择超参数的步骤：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;1. 将训练集分成 10 等份，即「折（fold）」；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;2. 从备选的所有超参数集中，选择一组超参数；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;3. 在给定一组超参数后，用训练数据的前 9 折训练你的模型；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;4. 用第 10 折，或单独拿出的数据（hold-out）折去评估模型；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;5. 用同一组超参数重复步骤（3）和（4）10 次，每次单独拿出不同的数据折（10 折都要用一次）做评估；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;6. 总计所有 10 次循环的结果，并作为该超参数集的性能指标；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;7. 对于所有备选的超参数集，重复步骤（2）至（6）；&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;下面是伪代码：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;#  pseudocode for cross-validation&lt;br/&gt;all_folds = split_into_k_parts(all_training_data)&lt;br/&gt; &lt;br/&gt;for set_p in hyperparameter_sets:&lt;br/&gt;    model = InstanceFromModelFamily()&lt;br/&gt; &lt;br/&gt;    for fold_k in all_folds:&lt;br/&gt;        training_folds = all_folds besides fold_k&lt;br/&gt;        fit model on training_folds using set_p&lt;br/&gt;        fold_k_performance = evaluate model on fold_k&lt;br/&gt; &lt;br/&gt;    set_p_performance = average all k fold_k_performances for set_p&lt;br/&gt; &lt;br/&gt;select set from hyperparameter_sets with best set_p_performance&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;宏观层面：解决问题&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;现在我们要撇开单个模型，甚至模型族。我们将在解决问题层面讨论迭代。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;通常，第一个构建的模型并不是最好的，即使采用交叉验证调试过参数。这是因为拟合模型参数和调试超参数只是整个机器学习问题解决工作流程的两个部分。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;还有其它的几种迭代技术，可以利用它们来找到最佳性能的解决方案。我们认为下面的两种技术可以比较容易地提高预测性能。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;尝试不同的模型族&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;机器学习中有一个概念称为「无免费午餐定理（NFL/No Free Lunch theorem）」。人们对 NFL 定理有不同的解释，但我们关心的是：没有一个模型族是最适合每一个问题的。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;由于各种因素，如数据类型、问题域、稀疏数据、甚至收集的数据量，不同的模型族会有不同的表现。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;因此，为改进给定问题的解决方案，最简单方法之一是尝试几个不同的模型族。这个迭代层面要高于之前其它的层面。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;下面是伪代码：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;# eudocode for selecting model family&lt;br/&gt;training_data, test_data = randomly_split(all_data)&lt;br/&gt;&lt;br/&gt;list_of_families = logistic regression,&lt;br/&gt;decision tree,&lt;br/&gt;SVM,&lt;br/&gt;neural network, etc...&lt;br/&gt;&lt;br/&gt;for model_family in list_of_families:&lt;br/&gt;best_model = tuned with cross-validation on training_data&lt;br/&gt;&lt;br/&gt;evaluate best_model from each model_family on test_data&lt;br/&gt;select final model&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;请注意，这里的交叉验证步骤与上一节中的交叉验证步骤相同。这种美丽的嵌套迭代（nested iteration）形式是解决机器学习问题的有效方法。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;组合模型&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;下一个改进解决方案的方法是将多个模型组合成一个整合模型（ensemble）。这是从拟合这些模型的迭代过程的直接扩展。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们将保存对不同的整合方法的详细讨论，但一个常见的整合形式是简单地取多个模型预测的平均值。当然，还有更先进的方法来组合你的模型，但是拟合多个模型的迭代方法是一样的。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这种组合的预测通常有与任何单个模型相比微小的性能提升。下面是构建一个简单的整合模型的伪代码：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;# pseudocode for building a simple ensemble modal&lt;br/&gt;training_data, test_data = randomly_split(all_data)&lt;br/&gt;&lt;br/&gt;list_of_families = logistic regression,&lt;br/&gt;decision tree,&lt;br/&gt;SVM,&lt;br/&gt;neural network, etc...&lt;br/&gt;&lt;br/&gt;for model_family in list_of_families:&lt;br/&gt;best_model = tuned with cross-validation on training_data&lt;br/&gt;&lt;br/&gt;average predictions by best_model from each model_family&lt;br/&gt;... profit! (often)&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;请注意，该过程的大部分内容与之前的技术完全相同！&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;实际上，这意味着你可以很容易地复制这两种技术。首先，你可以从各种不同的模型族构建最佳模型。然后你可以整合它们。最后，你可以在相同的测试集上评估单个模型和整合模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作为最后一个忠告：你应该总是单独拿出一个未经测试的测试集，以选择你的最终模型。我们建议在建模过程开始时将数据分成训练集和测试集。不到最后不要使用测试集。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;元数据层面：改进数据&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;更好的数据打败更好的算法，但这并不总是意味着更多的数据打败更好的算法。是的，更好的数据通常意味着更多的数据，但它也意味着更清洁的数据、更相关的数据、以及有更好的特征的数据。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;改进数据也是一个迭代过程。当你面对机器学习的更大挑战时，你会意识到，很难从一开始就完全获得所有数据。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;也许还有一些你没有想到的关键特征。也许你没有收集到足够的数据。也许你错误理解了数据集中的一个列，需要返回去重新向同事解释它。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一个伟大的机器学习从业者总是保持开放的心态，并不断改进数据集。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;收集更好的数据&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;收集更好的数据的能力是随时间、经验和更多领域专业知识而发展的技能。例如，如果你正在构建一个房地产定价模型，你应该收集关于房子本身、附近的社区、甚至过去支付的财产税等公开可用的信息。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;更好的数据的另一个要素是数据的整体清洁度（cleanliness）。这意味着减少丢失数据、降低测量误差，并尽力用主要指标（primary metric）替换代理指标（proxy metric）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这里有几个问题，可以激发你改进数据集的想法：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;正在收集的数据是否具有所需的所有特征？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你可以更好地清理数据吗？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你能减少测量误差吗？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;是否有可以删除的异常值？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;收集更多的数据是否廉价？&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;设计更好的特征&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;特征工程，或通过利用领域内知识从数据创建新特征，是用以改善模型的最有价值的活动。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;它通常是困难和耗时的，但它被认为是应用机器学习的关键。因此，作为机器学习的从业者，你有责任在你选择的领域继续学习。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这是因为当你了解更多关于该领域的信息时，你将培养对最具影响力的特征更好的直觉。你应该把学习过程也作为一个迭代过程，随着个人专长的增长而改善。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;人类层面：提升自己&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;现在我们已经到了机器学习中最重要的层面：人类层面。即使你忘记了这篇文章中的一切，我们希望你从这一节学习到东西。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;真相是：机器学习和数据科学是非常大和麻烦的主题。特别是如果你是一个初学者，你可能会感到不知所措。有这么多内容，每天都有新的发展在发生。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你知道吗？机器学习部分对于我们仍然非常艰难和困惑。但是没关系，因为我们坚信，最重要的迭代层面是在个人层面，即机器学习的实践者。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;因此，我们要以几块建议来结束这篇冗长的文章。我们希望这最后一部分可以帮助你保持洞察力，而不被这个领域超载的信息所淹没。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;#1. 不要停止学习&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;正像上文所说的，迭代建立在机器学习过程的每一个层面。你的个人技能也不例外。机器学习是一个深刻和丰富的领域，你练习得越多，一切就会变得越容易。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;#2. 不要从一开始就期望完美&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你不需要赢得你的第一次 Kaggle 比赛。即使你发现建立的模型完全不能用也没有关系，最宝贵的宝藏是你的个人成长和改善，这应该是你的主要关注点。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;#3. 什么都不知道也没关系&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;事实上，一个人几乎不可能知道关于机器学习的一切。关键是建立一个基础，以帮助你根据需要选择新的算法和技术。是的……理解迭代也是基础的一部分。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;#4. 至少尝试两次&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;挣扎在算法或任务之中？花费的时间比你想象的时间长吗？没问题，只记得至少多尝试一次。第二次尝试一切都变得更容易和更快，这是你进步的最佳方式。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;#5. 理论、实践和项目三者的循环&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们相信学习机器学习的最有效的方法是在理论、目标实践和更大的项目之间循环。这是掌握理论同时发展应用、实际技能的最快方式。你可以从我们的免费指南了解更多这种方法：https://elitedatascience.com/learn-machine-learning&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;迭代是一个简单而又美丽的概念，它能将机器学习的每一个层面粘合到一起：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;人类层面：反复练习以提升技能&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;元数据层面：持续改进数据和特征&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;宏观层面：探索不同的模型族和组合方式&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;微观层面：交叉验证以调试模型超参数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;模型层面：梯度下降以拟合模型参数&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;原文地址：https://elitedatascience.com/machine-learning-iteration&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="min-height: 1em; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="text-align: justify; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;</description><guid isPermaLink="false">http://chuansong.me/n/1408170342769</guid></item><item><title>推荐 | 九本不容错过的深度学习和神经网络书籍</title><link>http://chuansong.me/n/1408170442763</link><description>&lt;div class="rich_media_content " id="js_content"&gt;
&lt;section style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; background-color: rgb(117, 117, 118); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自aioptify&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：微胖、李亚洲、蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px;"&gt;针对 30 多本深度学习和神经网络书籍，我们（AI Optify 数据团队）使用不同指标（比如，在线评价、打分、所涉主题、作者影响力、出版年份、社交媒体是否提及等）训练机器学习算法，为每本书打分、排名。读者可能会喜欢我们的推荐，因为这份榜单基于数据并且客观。排名靠前的九本书如下。&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;1. 搭建你自己的神经网络（Make Your Own Neural Network）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;价格：45 美元&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;img data-ratio="1.2953367875647668" data-s="300,640" data-type="jpeg" data-w="193" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLl2QpOgomB665erWhcfz9Zqols0V0agiaZB0EjEZxkOiabYXGgYczOXuA/0?wx_fmt=jpeg"/&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一步步让你了解神经网络的数学原理并用 Python 搭建自己的神经网络。神经网络是深度学习和人工智能的关键元素。然而，几乎很少有人真正了解神经网络如何运作。本书从非常简单的思想开始，让你在趣味和从容不迫中，逐渐了解神经网络的运作原理。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;2. 神经网络设计（第二版）（Neural Network Design 2nd Edition)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;价格：28 美元&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="1.2315270935960592" data-s="300,640" data-type="jpeg" data-w="203" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLBBJ6Kr1SAJZlic7Q7QpQcMf6muyu0Iq4fwnXImxm8ATG9vsV629TtDQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;本书作者著有 Neural Network Toolbox for MATLAB 一书。本书清楚详细介绍了基本神经网络结构和学习规则。其中，作者条理清楚地介绍了主要的神经网络、训练方法以及如何用来解决实际问题。广泛介绍了前馈网络（包括多层和径向基网络）和循环网络的训练方法是本书的一大特点。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;3. 用于模式识别的神经网络（计量经济学高级教程）（Neural Networks for Pattern Recognition Advanced Texts in Econometrics）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;价格：58 美元&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;img data-ratio="1.4705882352941178" data-s="300,640" data-type="jpeg" data-w="170" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLKBIGiaaoOmo2eIPE4Yu4JRmaXth5b7oFYqicwNb4WbeU5PDW1G9vtlew/0?wx_fmt=jpeg"/&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;本书首次从统计模式识别角度全面介绍了前馈神经网络。在引介基本概念后，作者检视了概率密度函数的建模技巧以及多层感知机以及径向基函数网络模型的特性和优点。本书也介绍了各种不同形式的误差函数、误差函数极小化主要算法，神经网络的学习和泛化以及贝叶斯技巧及其应用。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;4. 神经网络：一个综合性基础（第二版）（Neural Networks: A Comprehensive Foundation (2nd Edition)&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;价格：48 美元&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img data-ratio="1" data-s="300,640" data-type="jpeg" data-w="250" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLnnu7vjnpN3pV1u2ukg9KSLv7tBIDJI814gr2MNofMk7e6iczo6GjhnA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;面向计算机工程、电子工程以及计算机科学专业研究生的神经网络课程，全面、易读、结构合理，全面更新的教程仍然是工程学视角下、最全面的神经网络介绍，本书已全面修订。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;5. 深度学习基础：设计下一代机器智能的算法（Fundamentals of Deep Learning: Designing Next-Generation Machine Intelligence Algorithms）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;价格：33 美元&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="1.3089005235602094" data-s="300,640" data-type="jpeg" data-w="191" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLta8ym0Ukiam7OJ90TpB7gpcSZ43frm3LkEFNpyZ8JsmibbxJkJwkJbCw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;随着神经网络在 21 世纪的振兴，深度学习已经成为一个极其活跃的研究领域，它正在为现代机器学习铺平道路。本书使用实例和论证说明帮助你理解这个复杂领域内的主要概念。掌握深度学习仍然是很复杂与困难的，不过如果你对机器学习有基本的理解，对 Python 编程语言比较熟悉，还能有一点微积分的数学背景，那么这本书将能很好地帮助你学习深度学习。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;6. 深度学习：自适应计算和机器学习系列（Deep Learning (Adaptive Computation and Machine Learning series)）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;价格：69 美元&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="1.3297872340425532" data-s="300,640" data-type="jpeg" data-w="188" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLdWfaEKuEPKzKbicRcsggo5EBDM3UjIyqoyDVevrwFUDKFic0hMgEumTA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;文中提供数学和学科概念背景知识，其涵盖了线性代数、概率论和信息论、数值计算和机器学习等相关的背景知识。它阐述了行业从业者使用的深度学习技术，包含了深度前馈网络，正则化，优化算法，卷积网络，序列建模和实用性方法等。同时它对深度学习实际应用如自然语言处理、语音识别、计算机视觉、在线推荐系统、生物信息学和视频游戏也做了一个详尽的调查分析。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;7. 神经锻造：前馈人工神经网络中的监督学习（Neural Smithing: Supervised Learning in Feedforward Artificial Neural Networks）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;价格：63 美元&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="1.2315270935960592" data-s="300,640" data-type="jpeg" data-w="203" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLR8ax9qyUSlFvRzHIH3S7f0SDGibJwZCAZAqP43d3miaWicLDlR5OLvwaw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;人工智能神经网络是非线形映射系统，它的结构简要的基于对人与动物大脑神经系统的观察。基础思路是简单单元的大规模系统以能生成许多复杂、有趣的行为的方式连接到一起。该书注重在前馈人工神经网络的一个子集，也就是多层感知器（MLP）。这是最普遍使用的神经网络，被应用于金融（预测）、制造业（流程控制）和科学（语音和图像识别）等多个领域。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;8. 人工神经网络基础（Fundamentals of Artificial Neural Networks）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;价格：45 美元&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="1.2315270935960592" data-s="300,640" data-type="jpeg" data-w="203" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLvSYa9f3X282naJKqqTvxk6ricxvribBQAnJKL70zalLDVX1NRluGeSEA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;作为 IEEE Transactions on Neural Networks 的书评编辑，Mohamad Hassoun 有机会去评估近年来出现的众多关于人工神经网络的书籍。现在，在 Fundamentals of Artificial Neural Networks 一书中，他通过清楚的分辨目前神经网络研究员使用的理论与实践的基本概念与主要方法，首次对人工神经网络范式提供了系统性的解释。这样的一本系统的、统一的书籍，尽管缺少对最近神经网络发展的描述，也依然很适合于学生与从业者。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;9. 深度学习：从业者的实用方法（Deep Learning: A Practitioner's Approach）&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;span style="font-size: 14px; text-align: justify;"&gt;价格：28 美元&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="1.3089005235602094" data-s="300,640" data-type="jpeg" data-w="191" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8k5Vvx1EonXhbLLWIicSIlLrstkQrYsx3ll5dPZLlhbwwaQRlzocTIiaW8NMuX1MZxib7dq9L4WHmOw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;你想寻找一本能阐述机器学习主要进展的核心书籍吗？Deep Learning: A Practitioner's Approach 为开发者和数据科学家提供最实用的信息，包括深度学习理论、最优方法和实用案例。作者 Adam Gibson 和 Josh Patterson 以非学术方式介绍了最新的相关论文和技术，并在他们的 DL4J 库中实现核心数学方法。如果你在嵌入式，桌面和大数据/ Hadoop spaces 工作，并真正想了解深度学习，那么这就是你想要的书。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="min-height: 1em; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="text-align: justify; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/div&gt;</description><guid isPermaLink="false">http://chuansong.me/n/1408170442763</guid></item><item><title>资源 | 程序员实用深度学习免费课程：从入门到实践</title><link>http://chuansong.me/n/1408170542769</link><description>&lt;div class="rich_media_content " id="js_content"&gt;
&lt;section style="color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="border: 0px currentcolor; font-family: 微软雅黑; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; min-height: 1em; font-size: 1em; border: currentcolor; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; background-color: rgb(117, 117, 118); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自Course&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; font-family: inherit; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; text-align: center; line-height: 1.75em; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：李泽南、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;欢迎来到为期 7 周的「程序员实用深度学习课程，第 1 部分」。这一部分课程由 Jeremy Howard（Kaggel 最初两届比赛冠军选手；Enlitic 的创始人）讲授。在课程中，即使你没有研究生水平的数学背景，也可以学习如何建立最先进的模型，当然这个过程并不简单。最后，最重要的是，这些课程全部都是免费的！&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(123, 12, 0); font-size: 16px;"&gt;&lt;span style="color: rgb(123, 12, 0);"&gt;课程官网：&lt;/span&gt;http://course.fast.ai/&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;br/&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;做好准备：如何设置亚马逊云服务 (AWS) 深度学习服务器&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="font-size: 13px; line-height: normal; font-family: 'Helvetica Neue'; color: rgb(0, 162, 255);"&gt;&lt;span style="color: rgb(123, 12, 0); font-size: 14px;"&gt;视频链接：https://www.youtube.com/watch?v=8rjRfW4JM2I&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在你开始第一节课之前，你需要一台可以深度学习的机器（也就是说，带有 Nvidia GPU 的计算机）。这部分的课程当中讲述的大部分内容都是以使用亚马逊云服务 (AWS) 为例。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这个视频详细介绍了设置深度学习服务器的各个步骤，使用最近发布的一个叫做「P2」的亚马逊云服务 (AWS) 产品，带有非常强大的 GPU，还有超大内存。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这个视频以及我们大多数的内容，都将 us-west-2 (Oregon) 设置为了默认区域。如果你在欧洲，可以使用 eu-east-1 (Ireland)，使用 setup_p2_ireland.sh，而不是 setup_p2.sh。目前，AWS 的 p2 只在 3 个地区可以使用，如果你在美国或是欧洲以外的其他地方，你还可以使用这些地区的 Amazon 系统映像 (AMI)，但是可能会有延时。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;注意：AWS 需要确认用户信息真实性，所以如果你是 AWS 新用户的话，你需要对进入 P2 提出特殊的请求。视频中已经对如何发送这一请求做出了展示，但是要注意的是现在有一点变化：现在你可以直接在表格当中进行请求，在视频中没有显示出来。使用视频中的「use case description」，在你的请求被处理之前，不能设置 P2 服务器。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;PS：如果你有 Azure 账户的话，可以用新的 GPU 服务器来代替，它们的运作方式几乎完全相同。如果你希望采用这种方式的话，维基和论坛上面有相关的细节。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;0、为什么要研究深度学习？卷积简介&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;视频链接：https://www.youtube.com/watch?v=ACU-T9L4_lI&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这个课程分为两部分：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;第一部分为深度学习的高度概述&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;第二部分将简要介绍卷积运算（convolution operation）和随机梯度下降法（Stochastic Gradient Descent）算法&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;本课的音质的画质与其他课程相比稍差一些。另外，本课当中涉及到的材料在其他的课程当中将会有更加详细地讲述。你在看完第 1 课和第 2 课的视频之后，就会发现事先看这个视频的用处。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;1、识别猫和狗&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;视频链接：https://www.youtube.com/watch?v=kzt3-FHdAeM&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在课程开始之前，请确认已做好深度学习服务器设置，请参阅 AWS 课程：http://course.fast.ai/lessons/aws.html。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在课程开始前，请阅读入门 http://course.fast.ai/start.html。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;概论&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;视频链接：https://www.youtube.com/watch?v=Th_ckFbc6bI&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;课程对深度学习进行了简要介绍。随后，我们将展示如何启动、停止和管理 AWS 实例，如何将数据复制到其中（如果你已经熟悉 AWS，那么你可以快速完成这一部分）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;下一部分的讨论的是如何为本课程（以及我们将要处理的所有计算机视觉项目）的数据进行结构化。这是最重要的步骤——如果你的数据有问题，你将无法训练任何模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;然后进入第一个深度学习模型。我们将学习如何从大量图片中区分猫和狗。我们无需理解数学细节，而是通过学习使用计算机完成任务，使用「微调」，这也许是任何深度学习实践者最重要的技能。一旦我们构建了一个可以从大量猫图中找出狗图的模型，我们就会退后一步，了解最初的「预训练」模型，并验证它在未经任何微调的情况下可以做什么。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;2、卷积神经网络&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;视频链接：https://www.youtube.com/watch?v=e3aM6XTekJc&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在上节课后，你的目标是在区分猫狗的竞赛中达到排名前 50%。在这节课上，Jeremy 将会展示他处理这一任务的作品。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在展示一个成功的模型之后，我们接下来会学到关于分类任务中最常用的损失函数的一些关键信息，同时学习如何使用可视化来了解你的模型的成功和失败之处。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在课程的下半部分，我们将深入了解 CNN 的细节和微调。我们将首先讨论为何通常需要从与训练网络（而不是随机权重）开始，观察微调如何让模型保持层次化，并调节权重以使各层协调。我们将学习为何需要微调，这包括神经网络的三大要素：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;致密层（或全连接层）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;随机梯度下降（SGD）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;激活功能（或非线性）&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;3、欠拟合与过拟合&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;视频链接：https://www.youtube.com/watch?v=6kwQEBMandw&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们已经学到构建 CNN 的几种办法——现在需要全面了解它是如何工作的了。在本节我们详细介绍了卷积的作用，以及它是如何与最大池化（max pooling）一起构建 CNN 的。我们还将了解 softmax 激活函数，它对于在分类模型中获得良好结果是至关重要的（分类模型是设计用于将数据项分为不同类，即离散组的任何模型）。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;如果你对于卷积操作不太理解，你可以先跳到第四课的开头。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;随后，我们将深入了解创建一个有效模型所需的最重要技能：处理欠拟合与过拟合。首先构建一个过拟合模型（这样我们就会知道我们的模型足够有效，可以被训练），然后逐渐使用一些策略来减少过拟合。在本节中，最重要的部分是应对过拟合的技术列表。我们建议你可以把这份列表抄写到一个方便的地方，随时参考使用，同时确保自己了解其中所有方法的意义。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们将展示两种应对过拟合最为有用的技术：dropout 和 data augmentation。我们还会讨论预计算卷积层技术。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;4、协同过滤、嵌入&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;视频链接：https://www.youtube.com/watch?v=V2h3IOBDvrA&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;卷积是学生最难以理解的概念之一，因此我们将从详细介绍卷积运算开始本节课程，在电子表格中实现一对卷积层和过滤器。接下来，我们对 SGD（和它的新变种）进行相同的介绍，你会看到加速 SGD 方式非常易用。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;随后，我们将进一步研究避免过拟合，并学习一些应对含有大量未标记数据，少量已标记数据的数据集（半监督学习任务）的技巧：「伪标记（pseudo-labeling）」与「知识蒸馏（knowledge distillation）」。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;最后，我们将离开计算机视觉，对推荐系统（特别是协同过滤）展开讨论，这是一种有用的技术，同时也是了解嵌入概念的好方式。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;5. 自然语言处理和循环神经网络入门&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;视频链接：https://www.youtube.com/watch?v=qvRL74L81lg&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们将开始结合我们之前所学过的东西，看我们能从中做出什么东西：我们发现我们得到了一个可以在 Kaggle 上获胜的结果！重点来了：在这个课程中，我们为 VGG 加入了批规范化（batch normalization），而且在原来的教室环境中，我们直接使用这个新实现更新了 VGG16 班。但是，在 MOOC 中，因为每个人都有自己的学习节奏，所以没有提供这个选择——如果你想使用这个版本的批规范化（强烈推荐），我们还创建了一个单独的 Vgg16BN 班。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;接下来，让我们回到协同过滤（collaborative filtering），然后我们可以发现我们可以快速轻松地构建一个能极大超越一点快速搜索所能得到的所有基准的模型。然后我们将我们注意力转向了对这些模型所创造的隐因素（latent factor）的可视化。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们还介绍了一下 Keras 功能 API，后面我们会大量用到它，因为其对架构的构建提供了很好的支持和灵活性。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;现在我们终于准备好开始自然语言处理（NLP）了，首先我们会了解前面我们开发的嵌入（embedding）可以如何帮助我们理解自然语言。我们在这个课程中所关注特定 NLP 任务是情感分析（sentiment analysis），但也有明白我们在这里学到的一切也适用于其它 NLP 分类任务（比如：垃圾信息过滤、欺诈检测或假新闻分类、在法律发现中寻找相关文档等）。我们也将了解 NLP 领域中迁移学习的等效技术，即预训练的词向量（pre-trained word vectors）的使用。这个工具能让模型实现更快的训练、减少数据需求、提升泛化能力。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;最后我们将介绍循环神经网络（RNN），其中包括了解神经网络架构的「视觉词汇（visual vocabulary）」——后续的课程会用到它们。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;6、构建循环网络&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;视频链接：https://www.youtube.com/watch?v=ll9y1U0SoVY&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;本课程首先介绍一个新工具 MixIterator，它允许我们完全实现在前几个课程里学到的伪标记技术（pseudo-labeling technique）。MixIterator 甚至能够进一步改进我们最好的 MNIST 模型，它已进入「学术排行榜」的前五。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;然后我们再次在嵌入系统中查看，使用电子表格来显示它们如何在「幕后」工作。我们在嵌入中查看协同过滤（collaborative filterings），就像查看自然语言处理（NLP）那样。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;在完成这些较短的任务后，我们就准备开始今天主要的任务，即构建循环神经网络。我们查看循环神经网络各种不同的模型，然后使用基本的 Keras 构建块从头开始创建每个模型。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;最后，我们首次查看 Theano，它是 Keras 用来实现计算的库。为了更好地理解 Theano 和循环神经网络的工作原理，我们在纯粹的 Theano 中创建自己的循环神经网络实现。学习 Theano 对于每个人都不是必需的，但是当你发现需要实现在 Keras 中还不存在的东西时，或为你的特定项目修改些什么的时候，Theano 可能就变得至关重要了。它有助于我们理解深度学习真正的运行方式。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;strong&gt;7、卷积神经网络架构；循环神经网络参数推导&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul class=" list-paddingleft-2" style="list-style-type: disc;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px; color: rgb(123, 12, 0);"&gt;视频链接：https://www.youtube.com/watch?v=Q0z-l2KRYFY&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这一课是第一部分课程的最后一课！本节分为两个部分：&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;ol class=" list-paddingleft-2" style="list-style-type: decimal;"&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们将一起来学习一些新型的卷积神经网络架构，学习如何处理多输入和多输出，如何生成热图，如何处理更大的图像。这些架构都是依赖于 Keras 的 functional API，这我们在上一节课中已经进行了学习，所以在这节课之前一定要确保掌握了这一工具。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们使用纯 Python 或者是 numpy 建立一个循环神经网络，包括自己进行梯度运算和随机梯度下降（SGD）的更新。之后我们会在 Theano 中建立一个门控循环单元（Gated Recurrent Unit，GRU）。&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这些较高级的话题都是进入第 2 部分课程学习的必需内容，第 2 部分课程将于 2017 年 2 月 27 日在旧金山大学数据中心开课，网络课程大约会在 2017 年 3 月更新。之后，我们将会继续对深度学习进行更加全面和深入的探讨，希望这些课程能让你从中受益！&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="text-align: justify; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; color: rgb(127, 127, 127); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-style: normal; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; max-width: 100% !important; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;</description><guid isPermaLink="false">http://chuansong.me/n/1408170542769</guid></item><item><title>独家专访 | 强化学习教父Richard Sutton：也许能在2030年之前实现强人工智能算法</title><link>http://chuansong.me/n/1403333942102</link><description>&lt;div class="rich_media_content " id="js_content"&gt;
&lt;section style="max-width: 100%; white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100%; box-sizing: border-box; border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; box-sizing: border-box; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; word-wrap: break-word !important;"&gt;&lt;p style="color: rgb(62, 62, 62); font-size: 1em; margin-top: -1.2em; max-width: 100%; box-sizing: border-box; min-height: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; font-weight: inherit; line-height: 1.75em; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); background-color: rgb(117, 117, 118); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心原创&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; box-sizing: border-box; font-family: inherit; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#7f7f7f"&gt;&lt;span style="font-size: 12px;"&gt;&lt;strong&gt;采访：ChainnZ、Yuxi&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-top: 5px; margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="color:#7f7f7f"&gt;&lt;span style="font-size: 12px;"&gt;&lt;strong&gt;编辑：Rui Chen、ChainnZ、Qintong Wu、&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;strong style="font-size: 12px; color: rgb(127, 127, 127); font-family: inherit; text-decoration: inherit;"&gt;吴攀、李泽南&lt;/strong&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Richard S. Sutton 教授被认为是现代计算的强化学习创立者之一。他为该领域做出了许多重大贡献，包括：时间差分学习（temporal difference learning）、策略梯度方法（policy gradient methods）、Dyna 架构。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;但惊人的是，Sutton 博士进入的第一个领域甚至与计算机科学无关。他先是获得了心理学学士学位，然后才转向计算机科学。但是，他并不认为自己转变了方向。他说：「和大多数心理学家关注的问题一样，我也对学习（learning）的工作方式很感兴趣，我在 1977 年获得了心理学学士学位；那时候学习在计算机科学领域还并不是很流行。因为我对人工智能或与人工智能相关的一切感到很好奇，所以我就选择了就读计算机科学的硕士，然后又读了博士。我对人工智能的看法受到了心理学领域关于人类和动物学习方面的影响——这也是我的秘密武器，因为人工智能领域的很多人都没有我这样的背景。我从心理学开始的，并且从中汲取了大量的灵感。」&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="1.0073952341824157" data-s="300,640" data-type="png" data-w="1217" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib4Lr2UVxI1Qc2h9qukwZKqGeYnZk66EJmzUfib5y3CPibxSvtSrjCC2osF6vrVEG44wLP2nd1vOb4Q/0?wx_fmt=png"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;1984 年，Sutton 博士在马萨诸塞大学安姆斯特分校（University of Massachusetts at Amherst）获得了博士学位。在 1985 年到 1994 年之间，他都是 GTE Laboratories 的计算机和智能系统实验室的技术组的主要成员。1995 年，他以资深研究科学家的身份回到了马萨诸塞大学安姆斯特分校并在那里一直呆到了 1998 年，之后他加入了 AT&amp;amp;T; Shannon Laboratory 担任人工智能部门的主要技术组成员。他的研究兴趣围绕着决策者与其环境交互时所面临的学习问题，他将其看作是人工智能的核心问题。他也对动物学习心理学、连接网络（connectionist networks）、以及广义上的能够持续改进自己对世界的表征和模型的系统。2003 年之后，他成了阿尔伯塔大学计算机科学系的教授和 iCORE Chair，在这里他领导着自己的「强化学习与人工智能实验室&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这个实验室的名字 RLAI 似乎在说明强化学习（RL）是所有人工智能问题的解决方案。但是，Sutton 博士在这次采访之中给了我们一个不同视角的解释。他指出有些人认为强化学习只是人工智能问题的强化，但实际上强化学习问题是实现人工智能的一种抽象的方法。他说：「我想说我们正在使用一种实现人工智能的方法，『强化学习与人工智能』是很有意思，其中的英语单词『and』意味着要么是两个单独的主题，要么就是互相包容的，它可能是『and』，也能是『or』。因为强化学习既是人工智能的一个子集，也是人工智能的一个源头。其中的关系挺模糊的。我们也仍还在寻找答案。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;强化学习是现在人工智能领域里面最活跃的研究领域之一，它是一种用于学习的计算方法，其中会有一个代理在与复杂的不确定环境交互时试图最大化其所收到的奖励（reward）。现在，如果你是一个强化学习的初学者，由 Richard Sutton 和 Andrew Barto 合著的《Reinforcement Learning : An Introduction》可能就是你的最佳选择。这本书提供了关于强化学习的简单明了的关键思想和算法的解释。Richard Sutton 和 Andrew Barto 的讨论从该领域的知识基础的历史延伸到了最新的发展的应用。但是，在 20 世纪 70 年代的时候，尽管机器学习被人所知且日益流行，但那时还没有出现强化学习这样的东西。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;近日，机器之心走进了阿尔伯塔大学与这位强化学习的教父聊了聊。让我们看看 Sutton 在这次独家专访中说了些什么。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;em&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：强化学习是如何起步的？编写算法的起点是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Sutton：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;这一直以来都是一个明显的思想——一个学习系统想要一些东西而且某些类型的学习方式缺失了。在 20 世纪 70 年代，Harry Klopf（1972,1975,1982）写了几篇解决类似问题的报告。他认识到适应性行为（adaptive behavior）的关键方面是失败（being lost），而那时候学习领域的研究者几乎都将关注的重心移到了监督学习上面。试错学习的关键思想却缺失了。我们试图弄明白其中的基本思想，然后发现他是对的。这一思想还从未在任何领域得到过研究，尤其是在机器学习领域；控制论、工程学和模式识别等领域也都没有研究——所有这些领域都忽略了这个思想。你可以在 50 年代看到一些早期的研究工作，那时候有人谈论过试验神经（trial neuro），但最后它还是变成了监督学习。它有目标和训练集，并且尝试记忆和从中进行归纳。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我们现在在谈论深度学习和强化学习，这很有意思。最开始的时候，情况也是类似——试图将强化学习和监督学习区分开。我们研究的目的是获得一个可以学习的系统，那就够了。所以强化学习找到了一种可以表现和最大化这个世界的方法，而监督学习只是记忆被给出的样本然后将其泛化到新样本上——但它们需要被告知该做些什么。现在，强化学习系统可以尝试很多不同的事物。我们必须尝试不同的事物，我们必须搜索动作和空间或定义学习来最大化世界。这个思想后来被丢弃了，Andrew Barto 和我则逐渐意识到这并没有出现在之前的研究中，而这是我们需要的。简单来说，这就是我们成为了先驱的原因。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;编辑注：实际上，自 1979 年以来，Sutton 博士就一直在开发和推广强化学习。和其他人一样，Sutton 博士感觉到强化学习已经在早期的控制论和人工智能研究中得到过了探索。尽管强化学习显然受到最早期的一些关于学习的计算研究的启发，但这些研究中的大部分都转向了其它方面，比如模式分类、监督学习和适应性控制，或他们整体上放弃对学习的研究。此外，那时候计算机的计算能力还是很有限的，所以要将强化学习应用到真实世界问题上是很困难的，因为强化学习涉及到大量试错，之后才能收敛到一个最优策略，这可能会需要非常长的时间。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：你怎么看待强化学习自 20 世纪 70 年代以来的发展？因为那时候看起来强化学习还需要长时间的发展而且进展缓慢，你为什么还会对其有信心？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Sutton：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;我不同意你所说的强化学习进展很慢的说法，但我确实同意计算资源给这一领域带来了很大的影响。我们需要时间等待可用的硬件。尽管那时候对深度学习来说还有一点早，它成功地使用了大量的计算提供助力。很长一段时间以来，人们都在说我们会在 2030 年拥有足以支持强人工智能的算力。但我认为这不仅仅依赖于廉价的硬件，还依赖于算法。我认为我们现在还没有强人工智能的算法，但我们也许能在 2030 年之前实现它。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：那么在 2030 年之前，硬件和软件哪一个更加关键？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Sutton：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;硬件优先还是软件优先，这是个大问题。我们需要软件来测试我们的硬件，我们也需要可用的硬件来推动人们研发软件。在有限的计算资源上研究和工作，即使最聪明的人也不能带来很大的价值。即使是在 2030 年我们有了合适的硬件，我们可能仍然需要 10 年以上的时间等待最聪明的研究者研究出算法。现在你理解我的推理过程了，你可以自己重新判断一下或改变你原来的想法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：近年来，人工智能已从心理学与神经科学的研究中受益良多，强化学习和卷积神经网络都是这样的例子。在你的新版《Reinforcement Learning: An Introduction》中，你也加入了相应的两个章节。心理学/神经科学对人工智能/强化学习有多重要？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Sutton：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;强化学习最初受到大脑运行机制的启发。目前认为大脑的运行机制类似于强化学习。这也被称作是大脑中世界系统的标准模型（standard model of world system）。之所以称之为标准模型并不是因为它是完美的，而是因为所有人都在使用它。这就像当你成名后所有人都知道你，大脑奖励机制的理论也是一样的套路。我们的大脑是研究心理学和动物行为学的完美模型。另外一个重要的事情是：这个模型是基于学习的，你可以进行规划，这是对于各种可能发生情况的响应。这也是一个强化我们进行规划的方式的模型，让我们可以从不同的后果中学习经验。考虑到两者的关系，人工智能研究者正在试图找出意识和心灵的本质。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;强化学习研究决策和控制，试图让机器在未知环境中做出最佳决策。深度强化学习研究在强化学习算法中使用了神经网络，让原始感官输入到原始电机输出的映射成为可能，消除了人工设计的过程。因此，如今深度强化学习（DRL）已经成为解决诸如游戏、决策问题、机器人控制等许多类型的问题的非常流行的方法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;编辑注：Sutton 认为强化学习和深度学习的整合是很好的技术演进。在特定领域内（如计算机视觉（CV）&lt;/span&gt;&lt;/span&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 12px;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;），他说道：「你完全可以不用强化学习就完成一个计算机视觉，用已有数据集监督学习正常训练的样本，但它不会有深度学习做出的结果那么好。我认为那会需要一点聪明和想象力才能做到。我认为计算机视觉如果使用一点强化学习的话，将会出现一个技术突破。」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Sutton：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;强化学习的最大优势在于，你可以在正常运行中学习。传统的深度学习方式需要使用标记好的数据集进行训练，而强化学习并不需要这样做。你可以发挥想象力改变设定，因为你虽然没有足够的数据，但你知道在正常情况下应该怎么做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;AlphaGo 在围棋上的胜利则是另一回事。毫无疑问 AlphaGo 是一个伟大的成就，它的水平提高速度是前所未有的。AlphaGo 的成就很大程度上归功于两种技术的整合：蒙特卡洛树搜索和深度强化学习。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;strong&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;机器之心：让我们以 AlphaGo 作为例子。为什么自我对弈很重要？自我对弈有什么缺陷吗？人工智能可以在自我学习的过程中持续提高性能吗？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Sutton：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;自我对弈可以生成无限多的训练数据。你不需要人力来为这些训练数据做标注，这是我们都希望得到的。由此观之，我们也可以让计算机在模拟真实环境中生存和竞争。当然，AlphaGo 缺乏一个关键要素：理解世界运行机制的能力，例如对物理定律的理解，以及对物体动作反馈的预测。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这里就出现了一个问题，你只能在虚拟环境中自我对弈，而在现实环境中我们没有类似与游戏的规则可循，现实生活是无限美好的（笑）。你知道当你按下手机上的接听键接听一个来电，将会有一些事会发生。但你无法预测会发生什么，这不是游戏里已经安排好的设定，很多事情你不知道结果会是什么。在游戏中自我对弈的缺陷就在于此。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;机器之心：深度学习需要大量数据。强化学习通常也需要提供大量样本进行训练。但是最近提出的 one shot learning（一次性学习）试图用很少的样本进行学习，这有点像是人类学习的方式了。你认为 one shot learning 可以用在强化学习中吗？&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Sutton：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;目前的学习方式是慢速的，我认为 one shot 方式可以加快机器学习的速度。人类可以从一些经验中很快地学习到大量知识，这意味着我们可以进行 one shot learning，从很少的经验中汲取大量有用知识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;strong&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;机器之心：谈完了强化学习的优势与技术突破，让我们来谈谈它的短处。你认为去强化学习和广义上的人工智能的短处在哪里？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Sutton：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;有几点非常重要，其中包括一个技术问题。先来谈谈大家都能理解的吧，这也是最大的问题。强化学习宽泛地说来，就是让机器可以理解这个世界，随后利用自己所学的知识完成人类指定的任务，纠正自主行为。像 AlphaGo 和深蓝这样的程序不需要知道世界运行的规律。它们知道下一步棋可能的落子位置，知道所有下一步会带来局势上的优劣。人造系统现在已经可以在这方面做得很好了。我们希望把这种决策和预测的方式应用到其他领域中去，但这需要一种新的机制，需要让机器对世界建模。我认为这是目前最大的问题。我们现在对动态的真实世界缺乏有效的模型，无法让机器在其中对抉择与抉择的后果进行模拟以不断学习。一旦我们做到了这一点，我们就会构建出更强大的人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;另外一些问题有关知识。机器要以何种方式作出预测？我们人类是以何种方式作出预测的？我们会试着用不同方法进行尝试看看后果，但不会全部试到全部结束。例如，当你走进一个房间，右手边是一杯水，有一把椅子，还有一些其他家具和人。你对房间里其他人的交流，或者和物体的交互会获得不同反馈，但人类只会去做一点点交互——也许永远不会拿起那杯水——因为我看着它就知道那是怎么回事了。这种从特定经验中学到的东西，我们称之为离策略（off-policy）学习，这种方式是目前强化学习领域中的最大挑战。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：这很有趣。我们还想知道更多的细节，如何更好地理解离策略（off-policy）学习？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Sutton：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;想要有效地了解离策略功能，你需要规模化的学习方式、需要使用未经处理的数据，而不必要总是有标签的图像的训练集，只需要通过纯粹地与世界互动来获取经验，并学习世界的运行方式……这种强化（学习）的方法是非常有趣的思路，人们应该尝试去做。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;机器之心：感谢你的精彩论述。最后我们还想问问，你对强化学习的初学者有什么建议？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;Sutton：&lt;/span&gt;&lt;/strong&gt;&lt;span style="font-size: 14px;"&gt;学习基础知识，先找一个简单便宜的应用。从数据中推导东西的方式是有已知确定结果的。想象一下电梯，也许在午夜时你可以把它关闭来节约能源，当有人来乘坐时再把它打开。所以你需要为此设定一个时间表，收集信息在这里就很重要了，如果没人乘坐，开启的电梯就是在浪费能源。训练数据也是同样的道理，你不应该在缺乏信息的时候进行训练，请记住这个准则。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; text-align: justify; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; color: rgb(62, 62, 62); line-height: 25.6px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文为机器之心原创，&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; font-size: 18px; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;</description><guid isPermaLink="false">http://chuansong.me/n/1403333942102</guid></item><item><title>访谈 | Jürgen Schmidhuber：人工智能在1991年就已经获得了「意识」</title><link>http://chuansong.me/n/1403334042183</link><description>&lt;div class="rich_media_content " id="js_content"&gt;
&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100%; border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; background-color: rgb(117, 117, 118); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自inverse&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：杜夏德、曹瑞&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.49921875" data-s="300,640" data-type="jpeg" data-w="1280" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib4Lr2UVxI1Qc2h9qukwZKq8ffDMia0j4MDv2yjK9NGVlp4jhMszOw6qmYSE3KjLaQ5xyVOphqfuxw/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;自从人类有了意识（有人会告诉你这是在 2000 年前，有人会说在 20 万年前）人类学者一直在试图理解和定义意识。对意识最简单纯粹的概念描述或许是世界情境中的自我意识。但是如果不能理解意识的深层机制，那么所谓的理解不过是停留在表面。这就是为什么神经科学家通过指向大脑内的物理现象成功地介入了关于意识的持续对话。但是把形而上学与物理联系起来，仍然会产生某种准科学、准哲学的结果，反而会弄巧成拙，让外人笑话。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;所以我们努力理解人工智能是否具有意识也就不足为奇，也难怪图灵测试越来越无法提供我们需要的答案。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;因为我们无法证明人工意识，很多工程师和专家对这种观点都是都条件反射地不屑一顾。但是 Jürgen Schmidhuber 不是这样，他很喜欢这个古怪的游戏。他今年 53 岁，自上世纪八十年代以来一直致力于人工智能研究，在谷歌、苹果、微软和 IBM 的产品中都能找到他研究成果的蛛丝马迹。作为瑞士卢加诺大学的人工智能教授、瑞士人工智能实验室 IDSIA 的科学主任，及致力于打造第一个实用通用人工智能的创业公司 NNAISENSE 的主席，Schmidhuber 认为，目前的人工智能系统已经具有意识。他相信他已经做到了，这就是他为什么会让人产生自我膨胀的印象，同时他也是这个领域最具争议的人物。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;Schmidhuber 所处的位置具有讽刺意味，如果他是正确的，他的信念将可能会被一些未来高级意识（hyperconscious AI）验证。Schmidhuber 是全球强调人工智能为数不多的人之一。所以 Inverse 问他在编程中是否看到了别人漏掉的什么东西，如果有，它与人类意识有什么关系。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img data-ratio="0.82265625" data-s="300,640" data-type="jpeg" data-w="1280" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib4Lr2UVxI1Qc2h9qukwZKqSTxFicUAKYSFd4nQdEvhZAyZE2CCvp9kCkIWRCU3OYsgqXUCickJMhJA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="text-align: justify; font-size: 12px;"&gt;Jürgen Schmidhuber 在国际健康论坛，2015&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;在你看来，未来人工智能的角色是什么？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;所谓智能—人类或人工—就是关于解决问题的能力。长期以来，我们已经尝试打造一个能解决所有问题的东西（general problem solver）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这种 problem solver 能基于之前学到的技能去学习新的技能，能无限制地添加新技能，变得越来越通用。当然，如果我们能成功，它将会改变一切，因为每个计算问题、每个职业都会受到影响。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;你说一些人工智能已经具有意识，你能解释一下为什么吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我认为我们在 25 年前就已经有了一个基本的有意识的学习系统。那个时候，我就提出通用的学习系统要包括两个模块。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;一个是一种循环网络控制器，学习将不断接收的数据——比如视频和疼痛传感器的疼痛信号，饥饿传感器上的饥饿信号——转换为行动。例如，当电池电量低时，传感器就会传来一些负数信息。这个网络能学习将所有这些输入及时转换成能成功的行动序列。例如，电池电量低时及时到达充电站，但如果路上没有碰到障碍，如椅子或桌子，就不需要唤醒疼痛传感器。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;智能体（agent）一生的目的是最大限度地享受快乐，同时将痛苦最小化。这个目标简单明确，但是很难实现，因为你需要学很多东西。你看一个小婴儿它需要花上几年的时间去学习这个世界的运作，学习怎么与世界互动以实现目标。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;自 1990 年以来，我们的智能体一直在尝试做同一件事情，使用一个额外的循环网络—一个无监督模块，去预测将要发生什么。它看起来在执行所有的行动，所有的观察都会有，使用这种经验来学习预测将要发生什么。因为它是循环网络，它能在一定程度上用所谓的预测编码以规律的形式预测未来。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;例如，如果你有一条关于 100 个落下的苹果的视频，所有的苹果总是以同一个方式落下，你就能学习预测这些苹果是怎么落下的，你也无需分别存储这些预测，也就是说你能把这个视频压缩非常小的几个字节。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img data-ratio="0.5337349397590362" data-s="300,640" data-type="jpeg" data-w="830" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib4Lr2UVxI1Qc2h9qukwZKqaEDsy74VrcwCopyquzniamh3m1lLBxLBynEyQHmIjiax7G0A1dyicsqUA/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span style="font-size: 12px; color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 12px; text-align: justify;"&gt;1963 年的 Jürgen 和他的父亲 Johann Schmidhuber 玩象棋 &lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;由于数据是从与环境的互动中得来，这种无监督模型网络——1990 年以来我一直叫它世界模型——能随着时间学习发现新的规则或者对称性、或各种重复。它能学习去用少量计算资源编码数据，这里的计算资源指的是更少的存储或者更少的计算时间。过去学习中有意识的东西会随着时间的推移变得自动和具有潜意识。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;随着网络的进步，学习一个新的规律后，它可以通过查看无监督的世界模型在学会前后需要编码多少计算资源来测量其新洞察力的深度，前后的差异就是网络的「乐趣」。其洞察力的深度是一个数字，直奔第一个网络，也就是控制器，控制器的任务是将所有的反馈信号最大化，包括从各种内在的愉悦时刻（joy moment）和该网络之前没有的洞察力而来的反馈信号。愉悦时刻类似于一个科学家发现一个以前未知的新物理定律。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;你能帮我在我的意识和经验的范围内理解所有的处理吗？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;当你行走在这个世界中时，你会遇到很多张人脸，这意味着你做的一些处理工作，在大脑中构建某种循环子网络来压缩观测历史（称之为 compactify）确实有效。「面部编码器」（face encoder）会与原型人脸相对应。所以当一个新面孔出现的时候，你需要做的就是要将这张面孔与原型的差异进行编码。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;即便如此，我仍然不确定为什么我们能说这就是有意识。&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;关于意识有一件很重要的事情是智能体会注意到，在与世界的互动中有一件事总是存在，即智能体自己。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;出于数据压缩的目的，用循环世界模型网络（recurrent world-model network）挑出一些神经元对智能体本身进行编码是非常有效率的。它能够通过创造一个符号将整个行为和感知的历史以及属于智能体的其他符号都进行压缩：可能是手、脚等。在解决新问题的过程中，不管你什么时候激活这些与自我符号相关的神经元，智能体都在思考着自身。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;所以，在 1991 年的时候，我们就已经达到了这一点。当然，那只是意识的一种基本形式——不像你我的意识这样令人印象深刻，因为我们的大脑要比这些小人工智能体的大脑大得多。我们的大脑皮层中的连接可能多达 10 万亿种，但是目前最大的长短期记忆人工神经网络（Long-Short Term Memory, LSTM）也可能只拥有 10 亿种连接。相比较，你的大脑皮层要大 10 万倍，所以携带的意识当然也要比小小的人造大脑更加可观。但是几乎每 5 年，计算的成本就会便宜 10 倍。所以或许我们还需要 25 年的时间，才能第一次获得和大脑皮层连接一样多的长短期记忆人工神经网络。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;人造大脑的电子连接比大脑皮层的连接要快。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: center;"&gt;&lt;img data-ratio="0.49921875" data-s="300,640" data-type="jpeg" data-w="1280" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib4Lr2UVxI1Qc2h9qukwZKqVq7VvaGp4kZG7EhkibgFjbqTsStwIeDOHyZ8iauRbIA7CHal9wChAO3w/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="text-align: justify; font-size: 12px;"&gt;Schmidhuber 和仿真机器人&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;strong&gt;&lt;span style="font-size: 14px;"&gt;用技术行话来说，真正的挑战是「知觉难题」（hard problem of consciousness）。这就像是一种经验一样，哲学家们称之为感质（qualia）。当你拥有了一种经验之后——看日落、听你最喜欢的乐队唱你喜欢的歌、闻卡布奇诺的味道等等——就可以从一些存在的事物当中获取一些经验。只是目前原因我们还不清楚。哲学家 David Chalmers 认为这个问题是一个「难题」，换句话说：「身体上的感受为什么会让我们的内心生活更加丰富呢？」你是否相信这个模型还会让这些人工智能产生感质？&lt;/span&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;我认同这个观点。从行为上来讲，这些人工智能都非常的相似。当我们让这些人工智能和其他一些能够伤害它们的人工智能面对面的时候——例如在捕食与被捕食（predator-prey）的场景中——它们不想要受伤。当一个人工智能袭击另一个人工智能时，它对疼痛的感知就会上升——而第二个人工智能就会据此进行预测并且避免这种痛苦，比如说藏在窗帘或者是模拟相同的场景。所以说，从这些智能体的行为来看，它们并不喜欢这样。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;这是我们很长时间以来所看到的。我们的人工智能正在试图避免痛苦，并将愉悦最大化——包括开心或是内心的喜悦，从洞察力到模式——因为它们已经内置了可以最大化的效用函数（utility function）或是奖励函数（reward function）。人类也生来具有一种奖励函数。这些人工生命的行为至少从性质上来看和高等级的动物或者说是人类非常相似。所以无论如何，我们都应该相信这是可复制的。&lt;/span&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;img data-ratio="0.49921875" data-s="300,640" data-type="jpeg" data-w="1280" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib4Lr2UVxI1Qc2h9qukwZKqJnFPRu3elN0ibhFmgZFpewXElujcbEPypJqp03bdPqATlUKicrLvcA3Q/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;em&gt;&lt;span style="font-size: 14px; color: rgb(136, 136, 136);"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;strong&gt;&lt;em&gt;&lt;span style="font-size: 14px; color: rgb(136, 136, 136);"&gt;这就像是为了讨论思维又发明出了一门新的语言一样。当你在反省的时候，你会不会觉得自己就像是一台计算机一样？你是不是在想：「我大脑中的高级活动区正在处理这个问题，较低级的区域正在进行自动处理？」你是这样反省的吗？&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;是的。我经常想这些洞察力是否都是来源于「第一原理」（First Principles），我是否能够通过的思考重新发现它们。我相信我可以，虽然我知道很多人都被反思所欺骗。但是对我来说非常清晰的一点是：这应该就是我正在做的事情。对我来说，我们不需要其他的一些东西来解释意识。我深信，我们已经具备了所有理解意识的基本成分，并且这一进程 25 年前就开始了。只是神经科学领域的人对人工神经网络研究的进展知之甚少，他们对一些简单的原理也不是太关注。但是我相信他们一定会对此了解更多。至少，这是我希望能够发生的。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="text-align: justify; line-height: 1.75em;"&gt;&lt;span style="font-size: 14px;"&gt;最近在纽约，我在一场大会上谈到伦理和人工智能。我回答了现场提出的一个有些挑衅的问题，多多少少地重复了我从 20 世纪 80 年代以来持有的一个观点：「我必须要坦白：我的公司正在研发仿真机器人。我就是一个原型。虽然我可能没有意识，但是我很擅长伪装成具有意识的样子。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136); font-size: 14px;"&gt;&lt;em&gt;原文链接：https://www.inverse.com/article/25521-juergen-schmidhuber-ai-consciousness&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; text-align: justify; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/div&gt;</description><guid isPermaLink="false">http://chuansong.me/n/1403334042183</guid></item><item><title>业界 | 深度学习新应用：通过聆听机器声音精确分析故障</title><link>http://chuansong.me/n/1403334142175</link><description>&lt;div class="rich_media_content " id="js_content"&gt;
&lt;section style="max-width: 100%; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 28.4444px; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section data-color="rgb(117, 117, 118)" data-custom="rgb(117, 117, 118)" data-id="85660" style="max-width: 100%; border-width: 0px; border-style: initial; border-color: currentcolor; font-family: 微软雅黑; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;section style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; font-family: inherit; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-top: -1.2em; max-width: 100%; min-height: 1em; font-size: 1em; border-width: initial; border-style: initial; border-color: currentcolor; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(255, 255, 255); line-height: 22.4px; font-size: 1em; font-family: inherit; text-decoration: inherit; background-color: rgb(117, 117, 118); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;选自IEEE&lt;/span&gt;&lt;/p&gt;&lt;section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px; max-width: 100%; font-family: inherit; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;机器之心编译&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; text-align: center; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;参与：蒋思源&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; background-color: rgb(255, 255, 255); text-align: justify; line-height: 1.75em; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;img data-ratio="0.6225806451612903" data-s="300,640" data-type="jpeg" data-w="620" src="http://read.html5.qq.com/image?src=forum&amp;amp;q=5&amp;amp;r=0&amp;amp;imgflag=7&amp;amp;imageUrl=http://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gWib4Lr2UVxI1Qc2h9qukwZKqmxiblGa3lcT4dt5qtuHTqwia0qZ4EdWn4eILxZQibbM42hWVYZgiaJrfuQ/0?wx_fmt=jpeg"/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;在路上开着的车有时会突然抛锚，任何人都不愿用这种方式来学习汽车的日常维护知识。但是预防性或定期维护检查通常会错过许多可能出现的问题，因此以色列的一家初创公司提出了一个更好的想法：利用人工智能监控汽车可能会出问题的前兆声音。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;位于以色列卡法萨巴城（Kefar Sava）的一家初创公司 3DSignals，它的服务依赖于人工智能中的深度学习方法来理解问题机器的噪声模式并提前预测问题。3DSignals 已经开始与领先的欧洲汽车制造商讨论使用深度学习在自动化汽车工厂和汽车本身上检测预防出现问题的可能性。3DSignals 甚至与这些大公司谈论使用他们的服务自动检测未来的无人驾驶出租车车队的问题。3DSignals 的联合创始人和算法负责人 Yair Lavi 说：「如果你是无人驾驶出租车的乘客，那么你只会关心到达目的地，而不想报告维护问题」。所以，实际上在自动出租车中使用 3DSignals 解决方案对于出租车车队的拥有者来说是非常值得考虑的事情。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;深度学习通常是指人工神经网络。这些神经网络可以通过多个（深）层级的人工神经元过滤相关数据来学习并在特定任务变得更好。许多公司（如谷歌和 Facebook）使用深度学习开发人工智能系统，它们可以迅速在一百万在线图像中找到一个面孔，或一天内进行数百万次的汉英翻译。许多科技巨头也应用深度学习，从而使它们的服务能自动识别不同人类语言，并变得更加完善。但是很少有公司使用深度学习开发擅长检测其他声学信号（如机器或音乐的声音）的机器。Lavi 解释说这就是 3DSignals 的期望，希望能在深度学习聚焦于更广泛的声音模型上占据一席之地。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;「我认为世界上大多数人都是对图像进行深度学习，这是迄今为止最流行的应用。但部分行业正在研究深度学习声学，它们聚焦于语音识别和对话。我认为可能有很小一部分公司正在做更通用型的声学研究。这就是我的目标，成为通用型声学深度学习领军者。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;3DSignals 为每个客户安装超声麦克风（ultrasonic microphones），它可以检测高达 100 千赫兹的声波（人类听力范围在 20 赫兹和 20 千赫兹之间）。该公司的「物联网」服务将麦克风连接到计算设备，该计算设备可以处理一些数据并将信息上传到在线网络，然后深度学习算法就开始处理数据。客户可以使用网络连接设备（如智能手机或平板电脑）查看机器运行状况。&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;3DSignals 的第一批客户是重工业集团的操作机械，如工厂中的圆形切割刀片或发电厂的水力发电涡轮机。这些公司最开始是通过购买 3DSignals 不使用深度学习的第一层服务。相对于使用深度学习，第一层服务依赖于某些机器部件（例如圆形切割锯）的基本物理数据进行建模，从而预测某些部件何时开始磨损。这样就能使客户从第一天起就获得应有的价值。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;iframe allowfullscreen="" class="video_iframe" data-vidtype="1" frameborder="0" height="418" src="http://v.qq.com/iframe/preview.html?vid=f0360sxzzxd&amp;amp;width=500&amp;amp;height=375&amp;amp;auto=0" width="557"&gt;&lt;/iframe&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;第二层服务是用深度学习算法和麦克风的声音检测来自机器的奇怪或异常噪声。在声音模型上训练的深度学习算法能够识别机器一般问题的信号。但是同样是使用深度学习，只有第三层服务才能将声音分类为指向具体类型的问题。不过在能清楚地指出问题之前，客户需要首先将某些声音模式标记为属于特定类型的问题，从而帮助训练深度学习算法。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;Lavi 说：「在训练后，我们不仅能在问题发生时预测它是 A 类型的问题，我们还能预测在五小时后 A 类问题将发生。一些问题不会立即发生，它总有一个恶化的过程。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;训练后，3DSignals 深度学习算法能够以 98％的精度预先识别特定的问题。但是目前使用 3DSignals 系统的客户还没有开始利用这种分类能力，他们还在手动标记特定的问题与特定的声音信号来建立训练数据集。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;这家成立已经一年的创业公司只有 15 名员工，但是增长相当快，并且从投资者 Dov Moran（首先发明 USB 闪存驱动器之一的以色列企业家）等人募集了 330 万美元。Lavi 和他的联合创始人已经关注了几个大市场，包括汽车和水力发电厂以外的能源部门。他们计划在 2017 年某个时间进行 A 轮融资以吸引风险资本。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;如果一切顺利，3DSignals 可以在不断增长的市场中扩大其领先地位，为工厂、发电厂和汽车车主提供「预测性维护」。即将到来的无人驾驶汽车可能对此会更加感兴趣——它们需要在乘客不理睬汽车的问题时帮助检测这些问题的深度学习人工智能。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt;除此之外，3DSignals 还有机会在识别一般声音上取得深度学习方面的进步。这对小型初创公司已经很不错了。&lt;/span&gt;&lt;/p&gt;&lt;p style="line-height: 1.75em; text-align: justify;"&gt;&lt;span style="font-size: 14px;"&gt; Lavi 说：「对于我们来说，重要的是成为通用型声学深度学习的专家，因为目前还没有覆盖这一领域的研究文献。」&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;原文链接：http://spectrum.ieee.org/automaton/robotics/artificial-intelligence/deep-learning-ai-listens-to-machines-for-signs-of-trouble&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;&lt;br/&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style="color: rgb(136, 136, 136);"&gt;&lt;em&gt;&lt;span style="font-size: 14px;"&gt;&lt;/span&gt;&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); font-size: 16px; white-space: normal; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; text-align: justify; line-height: 25.6px; font-family: 微软雅黑; font-size: 14px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; color: rgb(127, 127, 127); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;©本文由机器之心编译，&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;em style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-style: normal; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;转载请联系本公众号获得授权&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;br style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"/&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(127, 127, 127); line-height: 25.6px; font-family: 微软雅黑; text-align: justify; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;✄------------------------------------------------&lt;/span&gt;&lt;/p&gt;&lt;p style="margin-bottom: 5px; max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;加入机器之心（全职记者/实习生）：hr@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; color: rgb(217, 33, 66); line-height: 1.6; font-size: 12px; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;投稿或寻求报道：editor@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p style="max-width: 100%; min-height: 1em; color: rgb(62, 62, 62); white-space: normal; font-size: 18px; font-family: 微软雅黑; text-align: center; line-height: 1.75em; background-color: rgb(255, 255, 255); box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;strong style="max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;&lt;span style="max-width: 100%; font-size: 12px; color: rgb(217, 33, 66); line-height: 1.6; box-sizing: border-box !important; word-wrap: break-word !important;"&gt;广告&amp;amp;商务合作：bd@almosthuman.cn&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/div&gt;</description><guid isPermaLink="false">http://chuansong.me/n/1403334142175</guid></item></channel></rss>